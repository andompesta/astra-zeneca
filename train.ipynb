{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34505f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a50a0b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/conda/envs/geometric/lib/python3.9/site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/geometric/lib/python3.9/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/envs/geometric/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.0/770.0 kB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2022.10.31\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb47ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch import nn, Tensor, optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import Optional\n",
    "\n",
    "from src.datapipe import WikiDataset\n",
    "from src.utils.common import PAD\n",
    "from src.modules.graph_encoder import GraphEncoder\n",
    "from src.modules.seq_decoder import DecoderRNN\n",
    "from src.modules.graph_seq import GraphSeq\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606c2205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ando_cavallari/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"fd8e6949c75375b623a566795f8460842fee1e14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a234476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import bleu_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def compute_correct(\n",
    "    logits: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    pad_idx: int,\n",
    ") -> tuple[int, int]:\n",
    "    mask = (labels != pad_idx)\n",
    "    preds = logits.softmax(-1).argmax(-1).view(-1)\n",
    "    correct = ((preds == labels) * mask).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    return correct, total\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    steps_per_epoch: int,\n",
    "    scheduler: Optional[optim.lr_scheduler.LambdaLR] = None,\n",
    "    pad_idx: int = 0,\n",
    "    device: str = \"cuda\",\n",
    "    gradient_accumulation_steps: int = 1,\n",
    "    max_grad_norm: float = 20.,\n",
    ") -> dict[str, float]:\n",
    "    # setup\n",
    "    model = model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # got loss\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(\n",
    "        reduction=\"none\",\n",
    "        ignore_index=pad_idx,\n",
    "    )\n",
    "    loss_fn = loss_fn.to(device)\n",
    "\n",
    "    # metrics\n",
    "    total_loss = 0\n",
    "    n_pred_total = 0\n",
    "    n_pred_correct = 0\n",
    "    steps = 0\n",
    "\n",
    "    data_iter = iter(dataloader)\n",
    "\n",
    "    while (steps / gradient_accumulation_steps) < steps_per_epoch:\n",
    "        try:\n",
    "            batch_data = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(dataloader)\n",
    "            batch_data = next(data_iter)\n",
    "\n",
    "        batch_data = batch_data.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            trg_logits = model(\n",
    "                batch_data.x,\n",
    "                batch_data.src_seq,\n",
    "                batch_data.edge_index,\n",
    "                batch_data.bw_edge_index,\n",
    "                batch_data.batch,\n",
    "            )\n",
    "\n",
    "            trg_lable_t = batch_data.trg_seq.view(-1)\n",
    "            loss_t = loss_fn(\n",
    "                trg_logits.view(-1, model.vocab_size),\n",
    "                trg_lable_t,\n",
    "            )\n",
    "\n",
    "            loss_t = loss_t.mean(-1)\n",
    "\n",
    "            # accumulate the gradients\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                # scale the loss if gradient accumulation is used\n",
    "                loss_t = loss_t / gradient_accumulation_steps\n",
    "\n",
    "            loss_t.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                max_grad_norm,\n",
    "            )\n",
    "\n",
    "            if steps % gradient_accumulation_steps == 0:\n",
    "                # apply the accumulated gradients\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # update metrics\n",
    "        steps += 1\n",
    "        correct, total = compute_correct(\n",
    "            logits=trg_logits,\n",
    "            labels=trg_lable_t,\n",
    "            pad_idx=pad_idx,\n",
    "        )\n",
    "\n",
    "        total_loss += loss_t.item()\n",
    "        n_pred_total += total\n",
    "        n_pred_correct += correct\n",
    "\n",
    "        # clrea GPU memory\n",
    "        if steps % 50 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"batch : {steps}\")\n",
    "\n",
    "    steps /= gradient_accumulation_steps\n",
    "    total_loss = total_loss / steps\n",
    "    accuracy = n_pred_correct / n_pred_total\n",
    "\n",
    "    return dict(\n",
    "        train_loss=total_loss,\n",
    "        train_accuracy=accuracy,\n",
    "    )\n",
    "\n",
    "\n",
    "def eval(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    pad_idx: int = 0,\n",
    "    device: str = \"cuda\",\n",
    ") -> dict[str, float]:\n",
    "    # setup\n",
    "    model = model.eval()\n",
    "\n",
    "    # got loss\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(\n",
    "        reduction=\"none\",\n",
    "        ignore_index=pad_idx,\n",
    "    )\n",
    "    loss_fn = loss_fn.to(device)\n",
    "\n",
    "    # metrics\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    data_iter = iter(dataloader)\n",
    "\n",
    "    for batch_data in data_iter:\n",
    "        batch_data = batch_data.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            trg_logits = model(\n",
    "                batch_data.x,\n",
    "                batch_data.src_seq,\n",
    "                batch_data.edge_index,\n",
    "                batch_data.bw_edge_index,\n",
    "                batch_data.batch,\n",
    "            )\n",
    "\n",
    "            trg_lable_t = batch_data.trg_seq.view(-1)\n",
    "            loss_t = loss_fn(\n",
    "                trg_logits.view(-1, model.vocab_size),\n",
    "                trg_lable_t,\n",
    "            )\n",
    "\n",
    "            loss_t = loss_t.mean(-1)\n",
    "\n",
    "        # update metrics\n",
    "        steps += 1\n",
    "        total_loss += loss_t.item()\n",
    "\n",
    "        # update predictions\n",
    "        preds_t = trg_logits.softmax(-1).argmax(-1).detach_().cpu().numpy()\n",
    "        labels_t = batch_data.trg_seq.detach_().cpu().numpy()\n",
    "\n",
    "        for pred_i, label_i in zip(preds_t, labels_t):\n",
    "            # this is wrong, but will give a reference of the predictions\n",
    "            preds.append(pred_i[label_i != pad_idx].tolist())\n",
    "            labels.append(label_i[label_i != pad_idx].tolist())\n",
    "\n",
    "        # clrea GPU memory\n",
    "        if steps % 50 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"eval batch : {steps}\")\n",
    "\n",
    "    total_loss = total_loss / steps\n",
    "    accuracy = accuracy_score(\n",
    "        np.concatenate(labels),\n",
    "        np.concatenate(preds),\n",
    "    )\n",
    "    blue_score = np.array([\n",
    "        bleu_score.sentence_bleu([label], pred)\n",
    "        for pred, label in zip(preds, labels)\n",
    "    ]).mean()\n",
    "\n",
    "    return dict(\n",
    "        eval_loss=total_loss,\n",
    "        eval_accuracy=accuracy,\n",
    "        eval_blue_score=blue_score,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab487d48",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "*Goal* overfit a single batch to verify code correctnes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b45c38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/wiki\"\n",
    "DATASET_NAME = \"dev\"\n",
    "VOCAB_PATH = \"data/wiki/entity_2_id.bin\"\n",
    "BATCH_SIZE = 5\n",
    "SHUFFLE = False\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\"\n",
    "ACCUMULATION_STEPS = 1\n",
    "MAX_GRAD_NORM = 20.\n",
    "STEPS_PER_EPOCH = 4\n",
    "EPOCHS = 500\n",
    "PAD_IDX = 0\n",
    "\n",
    "EMB_DIM = 6\n",
    "GRAPH_CONV_LAYERS = 1\n",
    "RNN_LAYERS = 1\n",
    "RNN_DROPOUT = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c8115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"astrazeneca\"\n",
    "experiment_name = \"single-batch\"\n",
    "\n",
    "trials = [\n",
    "    # trial setup\n",
    "    dict(\n",
    "        job_type=\"train\",\n",
    "        project=project,\n",
    "        group=experiment_name,\n",
    "        notes=\"test training pipeline with a single batch on simple model\",\n",
    "        config=dict(\n",
    "            dataset_base_path=DATASET_PATH,\n",
    "            dataset_name=DATASET_NAME,\n",
    "            vocab_path=VOCAB_PATH,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=SHUFFLE,\n",
    "            learning_rate=LR,\n",
    "            device=DEVICE,\n",
    "            accumulation_steps=ACCUMULATION_STEPS,\n",
    "            max_grad_norm=MAX_GRAD_NORM,\n",
    "            epochs=EPOCHS,\n",
    "            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "            pad_idx=PAD_IDX,\n",
    "            emb_dim=EMB_DIM,\n",
    "            graph_conv_layers=GRAPH_CONV_LAYERS,\n",
    "            rnn_layers=RNN_LAYERS,\n",
    "            rnn_dropout=RNN_DROPOUT,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c00d8644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandompesta\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ando_cavallari/astra-zeneca/wandb/run-20230202_131502-3txc101t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andompesta/astrazeneca/runs/3txc101t\" target=\"_blank\">dancing-mandu-1</a></strong> to <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/3txc101t\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/3txc101t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\tacc:0.14102564102564102 \t loss:4.962750554084778\n",
      "epoch:1\tacc:0.17307692307692307 \t loss:4.958779573440552\n",
      "epoch:2\tacc:0.10897435897435898 \t loss:4.954402565956116\n",
      "epoch:3\tacc:0.07692307692307693 \t loss:4.9494359493255615\n",
      "epoch:4\tacc:0.07692307692307693 \t loss:4.943694114685059\n",
      "epoch:5\tacc:0.07692307692307693 \t loss:4.936980724334717\n",
      "epoch:6\tacc:0.07692307692307693 \t loss:4.929075241088867\n",
      "epoch:7\tacc:0.07692307692307693 \t loss:4.919732332229614\n",
      "epoch:8\tacc:0.07692307692307693 \t loss:4.908666014671326\n",
      "epoch:9\tacc:0.07692307692307693 \t loss:4.8955559730529785\n",
      "epoch:10\tacc:0.07692307692307693 \t loss:4.880047798156738\n",
      "epoch:11\tacc:0.07692307692307693 \t loss:4.861753702163696\n",
      "epoch:12\tacc:0.07692307692307693 \t loss:4.840230107307434\n",
      "epoch:13\tacc:0.07692307692307693 \t loss:4.815027475357056\n",
      "epoch:14\tacc:0.07692307692307693 \t loss:4.785659074783325\n",
      "epoch:15\tacc:0.07692307692307693 \t loss:4.751682639122009\n",
      "epoch:16\tacc:0.07692307692307693 \t loss:4.712716579437256\n",
      "epoch:17\tacc:0.07692307692307693 \t loss:4.668525815010071\n",
      "epoch:18\tacc:0.07692307692307693 \t loss:4.619050145149231\n",
      "epoch:19\tacc:0.07692307692307693 \t loss:4.5645283460617065\n",
      "epoch:20\tacc:0.07692307692307693 \t loss:4.505372047424316\n",
      "epoch:21\tacc:0.07692307692307693 \t loss:4.442216873168945\n",
      "epoch:22\tacc:0.07692307692307693 \t loss:4.3757500648498535\n",
      "epoch:23\tacc:0.07692307692307693 \t loss:4.306484937667847\n",
      "epoch:24\tacc:0.07692307692307693 \t loss:4.234678268432617\n",
      "epoch:25\tacc:0.07692307692307693 \t loss:4.16001832485199\n",
      "epoch:26\tacc:0.07692307692307693 \t loss:4.082042694091797\n",
      "epoch:27\tacc:0.07692307692307693 \t loss:3.999686896800995\n",
      "epoch:28\tacc:0.07692307692307693 \t loss:3.9113807678222656\n",
      "epoch:29\tacc:0.07692307692307693 \t loss:3.8150139451026917\n",
      "epoch:30\tacc:0.07692307692307693 \t loss:3.7079069018363953\n",
      "epoch:31\tacc:0.07692307692307693 \t loss:3.5868045687675476\n",
      "epoch:32\tacc:0.07692307692307693 \t loss:3.448000133037567\n",
      "epoch:33\tacc:0.07692307692307693 \t loss:3.287628650665283\n",
      "epoch:34\tacc:0.07692307692307693 \t loss:3.1022754311561584\n",
      "epoch:35\tacc:0.07692307692307693 \t loss:2.8899823427200317\n",
      "epoch:36\tacc:0.07692307692307693 \t loss:2.6515411734580994\n",
      "epoch:37\tacc:0.07692307692307693 \t loss:2.392338514328003\n",
      "epoch:38\tacc:0.07692307692307693 \t loss:2.124241530895233\n",
      "epoch:39\tacc:0.07692307692307693 \t loss:1.8689172565937042\n",
      "epoch:40\tacc:0.07692307692307693 \t loss:1.6540471017360687\n",
      "epoch:41\tacc:0.07692307692307693 \t loss:1.4969084560871124\n",
      "epoch:42\tacc:0.07692307692307693 \t loss:1.3927549123764038\n",
      "epoch:43\tacc:0.07692307692307693 \t loss:1.32487091422081\n",
      "epoch:44\tacc:0.10897435897435898 \t loss:1.2796001434326172\n",
      "epoch:45\tacc:0.1282051282051282 \t loss:1.2492396235466003\n",
      "epoch:46\tacc:0.1282051282051282 \t loss:1.2294151782989502\n",
      "epoch:47\tacc:0.1282051282051282 \t loss:1.2170954048633575\n",
      "epoch:48\tacc:0.1282051282051282 \t loss:1.2098648250102997\n",
      "epoch:49\tacc:0.1282051282051282 \t loss:1.2058014571666718\n",
      "epoch:50\tacc:0.12179487179487179 \t loss:1.2034967541694641\n",
      "epoch:51\tacc:0.11538461538461539 \t loss:1.2020264565944672\n",
      "epoch:52\tacc:0.1282051282051282 \t loss:1.2008874416351318\n",
      "epoch:53\tacc:0.1282051282051282 \t loss:1.1998716592788696\n",
      "epoch:54\tacc:0.1346153846153846 \t loss:1.1989347040653229\n",
      "epoch:55\tacc:0.14102564102564102 \t loss:1.1980927288532257\n",
      "epoch:56\tacc:0.14102564102564102 \t loss:1.1973635256290436\n",
      "epoch:57\tacc:0.1282051282051282 \t loss:1.1967441737651825\n",
      "epoch:58\tacc:0.1282051282051282 \t loss:1.1962150931358337\n",
      "epoch:59\tacc:0.1282051282051282 \t loss:1.195750206708908\n",
      "epoch:60\tacc:0.1282051282051282 \t loss:1.1953266561031342\n",
      "epoch:61\tacc:0.1282051282051282 \t loss:1.1949294209480286\n",
      "epoch:62\tacc:0.1282051282051282 \t loss:1.194550335407257\n",
      "epoch:63\tacc:0.14743589743589744 \t loss:1.1941857635974884\n",
      "epoch:64\tacc:0.16666666666666666 \t loss:1.1938341856002808\n",
      "epoch:65\tacc:0.1346153846153846 \t loss:1.1934941411018372\n",
      "epoch:66\tacc:0.1282051282051282 \t loss:1.1931639909744263\n",
      "epoch:67\tacc:0.1282051282051282 \t loss:1.1928418278694153\n",
      "epoch:68\tacc:0.1282051282051282 \t loss:1.1925259232521057\n",
      "epoch:69\tacc:0.1282051282051282 \t loss:1.1922143995761871\n",
      "epoch:70\tacc:0.1282051282051282 \t loss:1.1919061839580536\n",
      "epoch:71\tacc:0.1282051282051282 \t loss:1.1915998756885529\n",
      "epoch:72\tacc:0.1282051282051282 \t loss:1.1912945806980133\n",
      "epoch:73\tacc:0.1282051282051282 \t loss:1.190989375114441\n",
      "epoch:74\tacc:0.1282051282051282 \t loss:1.190683364868164\n",
      "epoch:75\tacc:0.1282051282051282 \t loss:1.1903756260871887\n",
      "epoch:76\tacc:0.1282051282051282 \t loss:1.1900654733181\n",
      "epoch:77\tacc:0.1282051282051282 \t loss:1.1897520124912262\n",
      "epoch:78\tacc:0.1282051282051282 \t loss:1.1894343197345734\n",
      "epoch:79\tacc:0.1282051282051282 \t loss:1.1891117095947266\n",
      "epoch:80\tacc:0.1282051282051282 \t loss:1.188783437013626\n",
      "epoch:81\tacc:0.1282051282051282 \t loss:1.18844872713089\n",
      "epoch:82\tacc:0.1282051282051282 \t loss:1.1881067752838135\n",
      "epoch:83\tacc:0.1282051282051282 \t loss:1.18775674700737\n",
      "epoch:84\tacc:0.1282051282051282 \t loss:1.1873980462551117\n",
      "epoch:85\tacc:0.1282051282051282 \t loss:1.1870297193527222\n",
      "epoch:86\tacc:0.1282051282051282 \t loss:1.1866568326950073\n",
      "epoch:87\tacc:0.1282051282051282 \t loss:1.1862851977348328\n",
      "epoch:88\tacc:0.1282051282051282 \t loss:1.1858936846256256\n",
      "epoch:89\tacc:0.1282051282051282 \t loss:1.1854996085166931\n",
      "epoch:90\tacc:0.1282051282051282 \t loss:1.1850911676883698\n",
      "epoch:91\tacc:0.1282051282051282 \t loss:1.1846840977668762\n",
      "epoch:92\tacc:0.1282051282051282 \t loss:1.1842634677886963\n",
      "epoch:93\tacc:0.1282051282051282 \t loss:1.1838240027427673\n",
      "epoch:94\tacc:0.1282051282051282 \t loss:1.183370590209961\n",
      "epoch:95\tacc:0.1282051282051282 \t loss:1.182908982038498\n",
      "epoch:96\tacc:0.1282051282051282 \t loss:1.1824271082878113\n",
      "epoch:97\tacc:0.1282051282051282 \t loss:1.1819340586662292\n",
      "epoch:98\tacc:0.1282051282051282 \t loss:1.181418925523758\n",
      "epoch:99\tacc:0.1282051282051282 \t loss:1.1808862686157227\n",
      "epoch:100\tacc:0.1282051282051282 \t loss:1.1803366243839264\n",
      "epoch:101\tacc:0.1282051282051282 \t loss:1.1797644793987274\n",
      "epoch:102\tacc:0.1282051282051282 \t loss:1.1791723370552063\n",
      "epoch:103\tacc:0.1282051282051282 \t loss:1.1785574555397034\n",
      "epoch:104\tacc:0.1282051282051282 \t loss:1.1779065430164337\n",
      "epoch:105\tacc:0.1282051282051282 \t loss:1.1772334575653076\n",
      "epoch:106\tacc:0.14102564102564102 \t loss:1.1765299141407013\n",
      "epoch:107\tacc:0.15384615384615385 \t loss:1.1757907569408417\n",
      "epoch:108\tacc:0.15384615384615385 \t loss:1.1750124990940094\n",
      "epoch:109\tacc:0.17307692307692307 \t loss:1.174189567565918\n",
      "epoch:110\tacc:0.1794871794871795 \t loss:1.173320472240448\n",
      "epoch:111\tacc:0.16025641025641027 \t loss:1.172389954328537\n",
      "epoch:112\tacc:0.17307692307692307 \t loss:1.1713870465755463\n",
      "epoch:113\tacc:0.1858974358974359 \t loss:1.1703011393547058\n",
      "epoch:114\tacc:0.22435897435897437 \t loss:1.1690971851348877\n",
      "epoch:115\tacc:0.19230769230769232 \t loss:1.167754203081131\n",
      "epoch:116\tacc:0.1794871794871795 \t loss:1.1662112176418304\n",
      "epoch:117\tacc:0.1794871794871795 \t loss:1.1644445061683655\n",
      "epoch:118\tacc:0.1987179487179487 \t loss:1.1624197661876678\n",
      "epoch:119\tacc:0.20512820512820512 \t loss:1.1601382791996002\n",
      "epoch:120\tacc:0.20512820512820512 \t loss:1.157646805047989\n",
      "epoch:121\tacc:0.20512820512820512 \t loss:1.1550232470035553\n",
      "epoch:122\tacc:0.1794871794871795 \t loss:1.152306228876114\n",
      "epoch:123\tacc:0.1794871794871795 \t loss:1.1495070159435272\n",
      "epoch:124\tacc:0.1794871794871795 \t loss:1.1465299725532532\n",
      "epoch:125\tacc:0.1794871794871795 \t loss:1.1432519853115082\n",
      "epoch:126\tacc:0.1794871794871795 \t loss:1.1395996510982513\n",
      "epoch:127\tacc:0.1794871794871795 \t loss:1.1355611383914948\n",
      "epoch:128\tacc:0.1794871794871795 \t loss:1.1311680972576141\n",
      "epoch:129\tacc:0.1794871794871795 \t loss:1.1264090836048126\n",
      "epoch:130\tacc:0.1794871794871795 \t loss:1.1212426126003265\n",
      "epoch:131\tacc:0.1794871794871795 \t loss:1.1156617999076843\n",
      "epoch:132\tacc:0.1794871794871795 \t loss:1.1096217632293701\n",
      "epoch:133\tacc:0.1794871794871795 \t loss:1.1028240025043488\n",
      "epoch:134\tacc:0.20512820512820512 \t loss:1.0953480005264282\n",
      "epoch:135\tacc:0.21794871794871795 \t loss:1.0873385965824127\n",
      "epoch:136\tacc:0.23076923076923078 \t loss:1.0789093971252441\n",
      "epoch:137\tacc:0.23076923076923078 \t loss:1.0701672732830048\n",
      "epoch:138\tacc:0.23076923076923078 \t loss:1.0612259805202484\n",
      "epoch:139\tacc:0.2564102564102564 \t loss:1.0520042479038239\n",
      "epoch:140\tacc:0.27564102564102566 \t loss:1.0424610376358032\n",
      "epoch:141\tacc:0.28205128205128205 \t loss:1.032762736082077\n",
      "epoch:142\tacc:0.28205128205128205 \t loss:1.0229298770427704\n",
      "epoch:143\tacc:0.2564102564102564 \t loss:1.0129993259906769\n",
      "epoch:144\tacc:0.2564102564102564 \t loss:1.0030207186937332\n",
      "epoch:145\tacc:0.2564102564102564 \t loss:0.9930334240198135\n",
      "epoch:146\tacc:0.2564102564102564 \t loss:0.9830747246742249\n",
      "epoch:147\tacc:0.2564102564102564 \t loss:0.9731812328100204\n",
      "epoch:148\tacc:0.2564102564102564 \t loss:0.9633863717317581\n",
      "epoch:149\tacc:0.2564102564102564 \t loss:0.9537192732095718\n",
      "epoch:150\tacc:0.2564102564102564 \t loss:0.9442041516304016\n",
      "epoch:151\tacc:0.2564102564102564 \t loss:0.9348612576723099\n",
      "epoch:152\tacc:0.2564102564102564 \t loss:0.9257077276706696\n",
      "epoch:153\tacc:0.2564102564102564 \t loss:0.9167580902576447\n",
      "epoch:154\tacc:0.28205128205128205 \t loss:0.908023789525032\n",
      "epoch:155\tacc:0.28205128205128205 \t loss:0.899514839053154\n",
      "epoch:156\tacc:0.28205128205128205 \t loss:0.8912388533353806\n",
      "epoch:157\tacc:0.28205128205128205 \t loss:0.8832017779350281\n",
      "epoch:158\tacc:0.28205128205128205 \t loss:0.8754074722528458\n",
      "epoch:159\tacc:0.28205128205128205 \t loss:0.8678587824106216\n",
      "epoch:160\tacc:0.28205128205128205 \t loss:0.8605578690767288\n",
      "epoch:161\tacc:0.28205128205128205 \t loss:0.8535061776638031\n",
      "epoch:162\tacc:0.3076923076923077 \t loss:0.8467042744159698\n",
      "epoch:163\tacc:0.3076923076923077 \t loss:0.8401507586240768\n",
      "epoch:164\tacc:0.3076923076923077 \t loss:0.833841472864151\n",
      "epoch:165\tacc:0.3076923076923077 \t loss:0.8277692496776581\n",
      "epoch:166\tacc:0.3076923076923077 \t loss:0.8219241052865982\n",
      "epoch:167\tacc:0.3076923076923077 \t loss:0.8162935674190521\n",
      "epoch:168\tacc:0.3076923076923077 \t loss:0.8108628988265991\n",
      "epoch:169\tacc:0.2948717948717949 \t loss:0.80561563372612\n",
      "epoch:170\tacc:0.28205128205128205 \t loss:0.8005339205265045\n",
      "epoch:171\tacc:0.3076923076923077 \t loss:0.7955994457006454\n",
      "epoch:172\tacc:0.3076923076923077 \t loss:0.7907935380935669\n",
      "epoch:173\tacc:0.3076923076923077 \t loss:0.7860979288816452\n",
      "epoch:174\tacc:0.3333333333333333 \t loss:0.7814952880144119\n",
      "epoch:175\tacc:0.3333333333333333 \t loss:0.7769690155982971\n",
      "epoch:176\tacc:0.34615384615384615 \t loss:0.7725038081407547\n",
      "epoch:177\tacc:0.358974358974359 \t loss:0.7680833339691162\n",
      "epoch:178\tacc:0.358974358974359 \t loss:0.763695240020752\n",
      "epoch:179\tacc:0.358974358974359 \t loss:0.7593288421630859\n",
      "epoch:180\tacc:0.358974358974359 \t loss:0.7549737989902496\n",
      "epoch:181\tacc:0.3717948717948718 \t loss:0.7506205886602402\n",
      "epoch:182\tacc:0.38461538461538464 \t loss:0.7462607175111771\n",
      "epoch:183\tacc:0.38461538461538464 \t loss:0.7418863922357559\n",
      "epoch:184\tacc:0.38461538461538464 \t loss:0.7374909520149231\n",
      "epoch:185\tacc:0.41025641025641024 \t loss:0.7330684214830399\n",
      "epoch:186\tacc:0.41025641025641024 \t loss:0.7286226749420166\n",
      "epoch:187\tacc:0.41025641025641024 \t loss:0.7241388261318207\n",
      "epoch:188\tacc:0.41025641025641024 \t loss:0.7196169346570969\n",
      "epoch:189\tacc:0.41025641025641024 \t loss:0.7150541841983795\n",
      "epoch:190\tacc:0.41025641025641024 \t loss:0.7104526907205582\n",
      "epoch:191\tacc:0.4230769230769231 \t loss:0.7057922780513763\n",
      "epoch:192\tacc:0.4230769230769231 \t loss:0.7010787129402161\n",
      "epoch:193\tacc:0.4358974358974359 \t loss:0.6963127851486206\n",
      "epoch:194\tacc:0.44871794871794873 \t loss:0.6914779543876648\n",
      "epoch:195\tacc:0.46153846153846156 \t loss:0.6865742802619934\n",
      "epoch:196\tacc:0.46153846153846156 \t loss:0.6815862059593201\n",
      "epoch:197\tacc:0.46153846153846156 \t loss:0.676499754190445\n",
      "epoch:198\tacc:0.46153846153846156 \t loss:0.671316385269165\n",
      "epoch:199\tacc:0.46153846153846156 \t loss:0.6660134792327881\n",
      "epoch:200\tacc:0.46794871794871795 \t loss:0.660610243678093\n",
      "epoch:201\tacc:0.5064102564102564 \t loss:0.6551227271556854\n",
      "epoch:202\tacc:0.5448717948717948 \t loss:0.6495712101459503\n",
      "epoch:203\tacc:0.5961538461538461 \t loss:0.6439546793699265\n",
      "epoch:204\tacc:0.6153846153846154 \t loss:0.6382793933153152\n",
      "epoch:205\tacc:0.6153846153846154 \t loss:0.6325122863054276\n",
      "epoch:206\tacc:0.6153846153846154 \t loss:0.6266316026449203\n",
      "epoch:207\tacc:0.6153846153846154 \t loss:0.6206136494874954\n",
      "epoch:208\tacc:0.6153846153846154 \t loss:0.6144430339336395\n",
      "epoch:209\tacc:0.6153846153846154 \t loss:0.6081108599901199\n",
      "epoch:210\tacc:0.5897435897435898 \t loss:0.60163813829422\n",
      "epoch:211\tacc:0.5897435897435898 \t loss:0.5951334685087204\n",
      "epoch:212\tacc:0.5897435897435898 \t loss:0.5885983854532242\n",
      "epoch:213\tacc:0.5769230769230769 \t loss:0.5821035653352737\n",
      "epoch:214\tacc:0.5833333333333334 \t loss:0.5755935162305832\n",
      "epoch:215\tacc:0.6153846153846154 \t loss:0.5690920948982239\n",
      "epoch:216\tacc:0.6153846153846154 \t loss:0.5626550614833832\n",
      "epoch:217\tacc:0.6282051282051282 \t loss:0.5562603771686554\n",
      "epoch:218\tacc:0.6666666666666666 \t loss:0.5499521940946579\n",
      "epoch:219\tacc:0.6666666666666666 \t loss:0.5436706840991974\n",
      "epoch:220\tacc:0.6666666666666666 \t loss:0.5374123305082321\n",
      "epoch:221\tacc:0.6730769230769231 \t loss:0.5311969220638275\n",
      "epoch:222\tacc:0.7051282051282052 \t loss:0.5250360071659088\n",
      "epoch:223\tacc:0.717948717948718 \t loss:0.5189307183027267\n",
      "epoch:224\tacc:0.717948717948718 \t loss:0.5128793567419052\n",
      "epoch:225\tacc:0.717948717948718 \t loss:0.5068855434656143\n",
      "epoch:226\tacc:0.7243589743589743 \t loss:0.500947467982769\n",
      "epoch:227\tacc:0.7564102564102564 \t loss:0.4950958266854286\n",
      "epoch:228\tacc:0.7435897435897436 \t loss:0.4892943650484085\n",
      "epoch:229\tacc:0.7435897435897436 \t loss:0.4834802970290184\n",
      "epoch:230\tacc:0.7371794871794872 \t loss:0.4777076095342636\n",
      "epoch:231\tacc:0.7307692307692307 \t loss:0.47194143384695053\n",
      "epoch:232\tacc:0.7371794871794872 \t loss:0.4661480337381363\n",
      "epoch:233\tacc:0.7243589743589743 \t loss:0.46028247475624084\n",
      "epoch:234\tacc:0.7435897435897436 \t loss:0.4542781487107277\n",
      "epoch:235\tacc:0.7692307692307693 \t loss:0.44803228974342346\n",
      "epoch:236\tacc:0.7692307692307693 \t loss:0.44139405339956284\n",
      "epoch:237\tacc:0.7692307692307693 \t loss:0.4341578036546707\n",
      "epoch:238\tacc:0.7628205128205128 \t loss:0.4260791316628456\n",
      "epoch:239\tacc:0.7884615384615384 \t loss:0.4172232449054718\n",
      "epoch:240\tacc:0.8012820512820513 \t loss:0.40841440856456757\n",
      "epoch:241\tacc:0.7948717948717948 \t loss:0.40105823427438736\n",
      "epoch:242\tacc:0.7884615384615384 \t loss:0.39411669969558716\n",
      "epoch:243\tacc:0.782051282051282 \t loss:0.3877641260623932\n",
      "epoch:244\tacc:0.782051282051282 \t loss:0.3814195916056633\n",
      "epoch:245\tacc:0.782051282051282 \t loss:0.3753635957837105\n",
      "epoch:246\tacc:0.7692307692307693 \t loss:0.3695518746972084\n",
      "epoch:247\tacc:0.7756410256410257 \t loss:0.36407507956027985\n",
      "epoch:248\tacc:0.7756410256410257 \t loss:0.3587920591235161\n",
      "epoch:249\tacc:0.7948717948717948 \t loss:0.3536979481577873\n",
      "epoch:250\tacc:0.7948717948717948 \t loss:0.34875690937042236\n",
      "epoch:251\tacc:0.7948717948717948 \t loss:0.343975193798542\n",
      "epoch:252\tacc:0.7948717948717948 \t loss:0.33934732526540756\n",
      "epoch:253\tacc:0.7948717948717948 \t loss:0.33484987169504166\n",
      "epoch:254\tacc:0.8012820512820513 \t loss:0.33047259598970413\n",
      "epoch:255\tacc:0.8205128205128205 \t loss:0.32621122151613235\n",
      "epoch:256\tacc:0.8205128205128205 \t loss:0.3220533952116966\n",
      "epoch:257\tacc:0.8205128205128205 \t loss:0.31799282133579254\n",
      "epoch:258\tacc:0.8205128205128205 \t loss:0.3140249699354172\n",
      "epoch:259\tacc:0.8333333333333334 \t loss:0.31014375388622284\n",
      "epoch:260\tacc:0.8461538461538461 \t loss:0.30634690821170807\n",
      "epoch:261\tacc:0.8461538461538461 \t loss:0.302628256380558\n",
      "epoch:262\tacc:0.8461538461538461 \t loss:0.2989884540438652\n",
      "epoch:263\tacc:0.8461538461538461 \t loss:0.2954805791378021\n",
      "epoch:264\tacc:0.8333333333333334 \t loss:0.2922937572002411\n",
      "epoch:265\tacc:0.8333333333333334 \t loss:0.2886617183685303\n",
      "epoch:266\tacc:0.8397435897435898 \t loss:0.28526730090379715\n",
      "epoch:267\tacc:0.8397435897435898 \t loss:0.2819723039865494\n",
      "epoch:268\tacc:0.8397435897435898 \t loss:0.27874813973903656\n",
      "epoch:269\tacc:0.8461538461538461 \t loss:0.27558377385139465\n",
      "epoch:270\tacc:0.8461538461538461 \t loss:0.2724841758608818\n",
      "epoch:271\tacc:0.8461538461538461 \t loss:0.269448421895504\n",
      "epoch:272\tacc:0.8461538461538461 \t loss:0.26647502928972244\n",
      "epoch:273\tacc:0.8461538461538461 \t loss:0.26356108486652374\n",
      "epoch:274\tacc:0.8461538461538461 \t loss:0.26070502400398254\n",
      "epoch:275\tacc:0.8461538461538461 \t loss:0.2579061761498451\n",
      "epoch:276\tacc:0.8461538461538461 \t loss:0.2551645264029503\n",
      "epoch:277\tacc:0.8461538461538461 \t loss:0.25247952342033386\n",
      "epoch:278\tacc:0.8653846153846154 \t loss:0.2498476766049862\n",
      "epoch:279\tacc:0.8717948717948718 \t loss:0.2472723349928856\n",
      "epoch:280\tacc:0.8717948717948718 \t loss:0.2447507567703724\n",
      "epoch:281\tacc:0.8717948717948718 \t loss:0.24228376150131226\n",
      "epoch:282\tacc:0.8717948717948718 \t loss:0.23986749351024628\n",
      "epoch:283\tacc:0.8717948717948718 \t loss:0.23750559985637665\n",
      "epoch:284\tacc:0.8653846153846154 \t loss:0.23521893471479416\n",
      "epoch:285\tacc:0.8461538461538461 \t loss:0.23318003118038177\n",
      "epoch:286\tacc:0.8589743589743589 \t loss:0.2308538258075714\n",
      "epoch:287\tacc:0.8461538461538461 \t loss:0.22866808995604515\n",
      "epoch:288\tacc:0.8589743589743589 \t loss:0.22651945427060127\n",
      "epoch:289\tacc:0.8525641025641025 \t loss:0.22442883253097534\n",
      "epoch:290\tacc:0.8525641025641025 \t loss:0.22239026054739952\n",
      "epoch:291\tacc:0.8589743589743589 \t loss:0.22039856761693954\n",
      "epoch:292\tacc:0.8461538461538461 \t loss:0.21845009177923203\n",
      "epoch:293\tacc:0.8461538461538461 \t loss:0.21654228121042252\n",
      "epoch:294\tacc:0.8461538461538461 \t loss:0.2146729715168476\n",
      "epoch:295\tacc:0.8461538461538461 \t loss:0.21284040063619614\n",
      "epoch:296\tacc:0.8461538461538461 \t loss:0.21104072034358978\n",
      "epoch:297\tacc:0.8461538461538461 \t loss:0.20927099511027336\n",
      "epoch:298\tacc:0.8461538461538461 \t loss:0.20753158628940582\n",
      "epoch:299\tacc:0.8461538461538461 \t loss:0.20582224056124687\n",
      "epoch:300\tacc:0.8461538461538461 \t loss:0.20413824170827866\n",
      "epoch:301\tacc:0.8461538461538461 \t loss:0.20247989147901535\n",
      "epoch:302\tacc:0.8461538461538461 \t loss:0.20084526762366295\n",
      "epoch:303\tacc:0.8461538461538461 \t loss:0.19923265278339386\n",
      "epoch:304\tacc:0.8461538461538461 \t loss:0.19764074310660362\n",
      "epoch:305\tacc:0.8461538461538461 \t loss:0.19606855884194374\n",
      "epoch:306\tacc:0.8461538461538461 \t loss:0.19451427459716797\n",
      "epoch:307\tacc:0.8461538461538461 \t loss:0.1929767243564129\n",
      "epoch:308\tacc:0.8461538461538461 \t loss:0.19145527482032776\n",
      "epoch:309\tacc:0.8461538461538461 \t loss:0.1899523064494133\n",
      "epoch:310\tacc:0.8589743589743589 \t loss:0.18850405514240265\n",
      "epoch:311\tacc:0.8589743589743589 \t loss:0.18727866187691689\n",
      "epoch:312\tacc:0.8653846153846154 \t loss:0.18561828508973122\n",
      "epoch:313\tacc:0.8717948717948718 \t loss:0.18416205793619156\n",
      "epoch:314\tacc:0.8717948717948718 \t loss:0.1826900839805603\n",
      "epoch:315\tacc:0.8717948717948718 \t loss:0.18123291805386543\n",
      "epoch:316\tacc:0.8717948717948718 \t loss:0.17979314550757408\n",
      "epoch:317\tacc:0.8717948717948718 \t loss:0.1783681884407997\n",
      "epoch:318\tacc:0.8717948717948718 \t loss:0.17695672065019608\n",
      "epoch:319\tacc:0.8717948717948718 \t loss:0.175556942820549\n",
      "epoch:320\tacc:0.8717948717948718 \t loss:0.17416449263691902\n",
      "epoch:321\tacc:0.8717948717948718 \t loss:0.17277615144848824\n",
      "epoch:322\tacc:0.8717948717948718 \t loss:0.1713964194059372\n",
      "epoch:323\tacc:0.8717948717948718 \t loss:0.17002790048718452\n",
      "epoch:324\tacc:0.8717948717948718 \t loss:0.1686636134982109\n",
      "epoch:325\tacc:0.8717948717948718 \t loss:0.16730890050530434\n",
      "epoch:326\tacc:0.8717948717948718 \t loss:0.16596000269055367\n",
      "epoch:327\tacc:0.8717948717948718 \t loss:0.16462009400129318\n",
      "epoch:328\tacc:0.8717948717948718 \t loss:0.16328447684645653\n",
      "epoch:329\tacc:0.8717948717948718 \t loss:0.16195372492074966\n",
      "epoch:330\tacc:0.8717948717948718 \t loss:0.16062621399760246\n",
      "epoch:331\tacc:0.8717948717948718 \t loss:0.15929856896400452\n",
      "epoch:332\tacc:0.8717948717948718 \t loss:0.1579670049250126\n",
      "epoch:333\tacc:0.8717948717948718 \t loss:0.15663906186819077\n",
      "epoch:334\tacc:0.8782051282051282 \t loss:0.1557082049548626\n",
      "epoch:335\tacc:0.8782051282051282 \t loss:0.15466298907995224\n",
      "epoch:336\tacc:0.8846153846153846 \t loss:0.152943454682827\n",
      "epoch:337\tacc:0.8846153846153846 \t loss:0.15135492756962776\n",
      "epoch:338\tacc:0.8910256410256411 \t loss:0.14984389021992683\n",
      "epoch:339\tacc:0.8974358974358975 \t loss:0.14823146909475327\n",
      "epoch:340\tacc:0.8974358974358975 \t loss:0.1466304026544094\n",
      "epoch:341\tacc:0.8974358974358975 \t loss:0.14530042931437492\n",
      "epoch:342\tacc:0.8974358974358975 \t loss:0.1434350162744522\n",
      "epoch:343\tacc:0.8974358974358975 \t loss:0.14253424480557442\n",
      "epoch:344\tacc:0.8974358974358975 \t loss:0.14211157709360123\n",
      "epoch:345\tacc:0.8974358974358975 \t loss:0.13979553431272507\n",
      "epoch:346\tacc:0.8974358974358975 \t loss:0.13763360679149628\n",
      "epoch:347\tacc:0.8974358974358975 \t loss:0.13596292212605476\n",
      "epoch:348\tacc:0.8974358974358975 \t loss:0.1344018578529358\n",
      "epoch:349\tacc:0.8974358974358975 \t loss:0.13293808698654175\n",
      "epoch:350\tacc:0.8974358974358975 \t loss:0.1315407045185566\n",
      "epoch:351\tacc:0.8974358974358975 \t loss:0.13023152574896812\n",
      "epoch:352\tacc:0.8974358974358975 \t loss:0.12889401242136955\n",
      "epoch:353\tacc:0.8974358974358975 \t loss:0.12765470147132874\n",
      "epoch:354\tacc:0.8974358974358975 \t loss:0.1264854073524475\n",
      "epoch:355\tacc:0.8974358974358975 \t loss:0.12546760588884354\n",
      "epoch:356\tacc:0.8974358974358975 \t loss:0.12463676556944847\n",
      "epoch:357\tacc:0.8974358974358975 \t loss:0.12304310500621796\n",
      "epoch:358\tacc:0.8974358974358975 \t loss:0.12215976789593697\n",
      "epoch:359\tacc:0.8974358974358975 \t loss:0.12080592475831509\n",
      "epoch:360\tacc:0.9038461538461539 \t loss:0.11987627483904362\n",
      "epoch:361\tacc:0.9230769230769231 \t loss:0.11882590688765049\n",
      "epoch:362\tacc:0.9230769230769231 \t loss:0.11765754967927933\n",
      "epoch:363\tacc:0.9230769230769231 \t loss:0.11682012863457203\n",
      "epoch:364\tacc:0.9230769230769231 \t loss:0.11595957353711128\n",
      "epoch:365\tacc:0.9230769230769231 \t loss:0.11475630104541779\n",
      "epoch:366\tacc:0.9230769230769231 \t loss:0.11381228081882\n",
      "epoch:367\tacc:0.9230769230769231 \t loss:0.1130344569683075\n",
      "epoch:368\tacc:0.9230769230769231 \t loss:0.11204064823687077\n",
      "epoch:369\tacc:0.9230769230769231 \t loss:0.11095998622477055\n",
      "epoch:370\tacc:0.9230769230769231 \t loss:0.11017469502985477\n",
      "epoch:371\tacc:0.9230769230769231 \t loss:0.1094578392803669\n",
      "epoch:372\tacc:0.9230769230769231 \t loss:0.10850858129560947\n",
      "epoch:373\tacc:0.9230769230769231 \t loss:0.10747471824288368\n",
      "epoch:374\tacc:0.9230769230769231 \t loss:0.10679415427148342\n",
      "epoch:375\tacc:0.9230769230769231 \t loss:0.10595771484076977\n",
      "epoch:376\tacc:0.9230769230769231 \t loss:0.10497292131185532\n",
      "epoch:377\tacc:0.9230769230769231 \t loss:0.10416406393051147\n",
      "epoch:378\tacc:0.9230769230769231 \t loss:0.10350316017866135\n",
      "epoch:379\tacc:0.9166666666666666 \t loss:0.10296839103102684\n",
      "epoch:380\tacc:0.9166666666666666 \t loss:0.10195312276482582\n",
      "epoch:381\tacc:0.9230769230769231 \t loss:0.10117349773645401\n",
      "epoch:382\tacc:0.9230769230769231 \t loss:0.10037679970264435\n",
      "epoch:383\tacc:0.9230769230769231 \t loss:0.09951512701809406\n",
      "epoch:384\tacc:0.9230769230769231 \t loss:0.09890718944370747\n",
      "epoch:385\tacc:0.9230769230769231 \t loss:0.09829630702733994\n",
      "epoch:386\tacc:0.9230769230769231 \t loss:0.09738051891326904\n",
      "epoch:387\tacc:0.9230769230769231 \t loss:0.09670889750123024\n",
      "epoch:388\tacc:0.9166666666666666 \t loss:0.09623683616518974\n",
      "epoch:389\tacc:0.9166666666666666 \t loss:0.09565318748354912\n",
      "epoch:390\tacc:0.9230769230769231 \t loss:0.09461998380720615\n",
      "epoch:391\tacc:0.9230769230769231 \t loss:0.09405826963484287\n",
      "epoch:392\tacc:0.9230769230769231 \t loss:0.09322265163064003\n",
      "epoch:393\tacc:0.9166666666666666 \t loss:0.0927346684038639\n",
      "epoch:394\tacc:0.9166666666666666 \t loss:0.09232135862112045\n",
      "epoch:395\tacc:0.9230769230769231 \t loss:0.09134120680391788\n",
      "epoch:396\tacc:0.9230769230769231 \t loss:0.0908046830445528\n",
      "epoch:397\tacc:0.9230769230769231 \t loss:0.09001540578901768\n",
      "epoch:398\tacc:0.9230769230769231 \t loss:0.08956268802285194\n",
      "epoch:399\tacc:0.9166666666666666 \t loss:0.08923722431063652\n",
      "epoch:400\tacc:0.9230769230769231 \t loss:0.08826439455151558\n",
      "epoch:401\tacc:0.9230769230769231 \t loss:0.08774157613515854\n",
      "epoch:402\tacc:0.9230769230769231 \t loss:0.08702033944427967\n",
      "epoch:403\tacc:0.9294871794871795 \t loss:0.08667763136327267\n",
      "epoch:404\tacc:0.9294871794871795 \t loss:0.08602796867489815\n",
      "epoch:405\tacc:0.9230769230769231 \t loss:0.08529944159090519\n",
      "epoch:406\tacc:0.9230769230769231 \t loss:0.08474438823759556\n",
      "epoch:407\tacc:0.9230769230769231 \t loss:0.0841443631798029\n",
      "epoch:408\tacc:0.9294871794871795 \t loss:0.08372981660068035\n",
      "epoch:409\tacc:0.9358974358974359 \t loss:0.08324902690947056\n",
      "epoch:410\tacc:0.9294871794871795 \t loss:0.08250758983194828\n",
      "epoch:411\tacc:0.9358974358974359 \t loss:0.08203082531690598\n",
      "epoch:412\tacc:0.9358974358974359 \t loss:0.08151155896484852\n",
      "epoch:413\tacc:0.9230769230769231 \t loss:0.0809283684939146\n",
      "epoch:414\tacc:0.9230769230769231 \t loss:0.08038290403783321\n",
      "epoch:415\tacc:0.9294871794871795 \t loss:0.07988683506846428\n",
      "epoch:416\tacc:0.9358974358974359 \t loss:0.07952452450990677\n",
      "epoch:417\tacc:0.9423076923076923 \t loss:0.07960139028728008\n",
      "epoch:418\tacc:0.9294871794871795 \t loss:0.07880167849361897\n",
      "epoch:419\tacc:0.9423076923076923 \t loss:0.07818334735929966\n",
      "epoch:420\tacc:0.9423076923076923 \t loss:0.07764667831361294\n",
      "epoch:421\tacc:0.9423076923076923 \t loss:0.07711579650640488\n",
      "epoch:422\tacc:0.9358974358974359 \t loss:0.07652786932885647\n",
      "epoch:423\tacc:0.9358974358974359 \t loss:0.07601269893348217\n",
      "epoch:424\tacc:0.9423076923076923 \t loss:0.075535848736763\n",
      "epoch:425\tacc:0.9423076923076923 \t loss:0.07503673434257507\n",
      "epoch:426\tacc:0.9358974358974359 \t loss:0.07456598803400993\n",
      "epoch:427\tacc:0.9487179487179487 \t loss:0.0741688646376133\n",
      "epoch:428\tacc:0.9487179487179487 \t loss:0.0737240668386221\n",
      "epoch:429\tacc:0.9423076923076923 \t loss:0.07322884909808636\n",
      "epoch:430\tacc:0.9423076923076923 \t loss:0.07273135147988796\n",
      "epoch:431\tacc:0.9487179487179487 \t loss:0.07227469049394131\n",
      "epoch:432\tacc:0.9551282051282052 \t loss:0.07185262627899647\n",
      "epoch:433\tacc:0.9487179487179487 \t loss:0.0718292947858572\n",
      "epoch:434\tacc:0.9423076923076923 \t loss:0.07868603058159351\n",
      "epoch:435\tacc:0.9358974358974359 \t loss:0.08427447266876698\n",
      "epoch:436\tacc:0.9487179487179487 \t loss:0.07762361131608486\n",
      "epoch:437\tacc:0.9487179487179487 \t loss:0.07420150376856327\n",
      "epoch:438\tacc:0.9551282051282052 \t loss:0.07319899834692478\n",
      "epoch:439\tacc:0.9551282051282052 \t loss:0.07085252553224564\n",
      "epoch:440\tacc:0.9615384615384616 \t loss:0.07031061872839928\n",
      "epoch:441\tacc:0.9615384615384616 \t loss:0.07010909542441368\n",
      "epoch:442\tacc:0.9551282051282052 \t loss:0.06957477331161499\n",
      "epoch:443\tacc:0.9551282051282052 \t loss:0.06909085065126419\n",
      "epoch:444\tacc:0.967948717948718 \t loss:0.06881419010460377\n",
      "epoch:445\tacc:0.9615384615384616 \t loss:0.06852584145963192\n",
      "epoch:446\tacc:0.9615384615384616 \t loss:0.06812149658799171\n",
      "epoch:447\tacc:0.9615384615384616 \t loss:0.06785532087087631\n",
      "epoch:448\tacc:0.9615384615384616 \t loss:0.06767149083316326\n",
      "epoch:449\tacc:0.9615384615384616 \t loss:0.06739981286227703\n",
      "epoch:450\tacc:0.9615384615384616 \t loss:0.06719478219747543\n",
      "epoch:451\tacc:0.9615384615384616 \t loss:0.06701464392244816\n",
      "epoch:452\tacc:0.9551282051282052 \t loss:0.06665405258536339\n",
      "epoch:453\tacc:0.9615384615384616 \t loss:0.06602371670305729\n",
      "epoch:454\tacc:0.9743589743589743 \t loss:0.06519302353262901\n",
      "epoch:455\tacc:0.967948717948718 \t loss:0.0645087119191885\n",
      "epoch:456\tacc:0.9807692307692307 \t loss:0.06404078379273415\n",
      "epoch:457\tacc:0.9807692307692307 \t loss:0.06365367956459522\n",
      "epoch:458\tacc:0.9807692307692307 \t loss:0.06328244879841805\n",
      "epoch:459\tacc:0.9807692307692307 \t loss:0.06291196495294571\n",
      "epoch:460\tacc:0.9807692307692307 \t loss:0.0625537633895874\n",
      "epoch:461\tacc:0.9807692307692307 \t loss:0.062204585410654545\n",
      "epoch:462\tacc:0.9807692307692307 \t loss:0.06186284031718969\n",
      "epoch:463\tacc:0.9807692307692307 \t loss:0.06152766663581133\n",
      "epoch:464\tacc:0.9807692307692307 \t loss:0.06119797099381685\n",
      "epoch:465\tacc:0.9871794871794872 \t loss:0.060871739871799946\n",
      "epoch:466\tacc:0.9871794871794872 \t loss:0.06054832320660353\n",
      "epoch:467\tacc:0.9871794871794872 \t loss:0.06022635381668806\n",
      "epoch:468\tacc:0.9935897435897436 \t loss:0.05990535952150822\n",
      "epoch:469\tacc:1.0 \t loss:0.05958443973213434\n",
      "epoch:470\tacc:1.0 \t loss:0.05926349200308323\n",
      "epoch:471\tacc:1.0 \t loss:0.05894217174500227\n",
      "epoch:472\tacc:1.0 \t loss:0.05862042028456926\n",
      "epoch:473\tacc:1.0 \t loss:0.05829841457307339\n",
      "epoch:474\tacc:1.0 \t loss:0.05797581747174263\n",
      "epoch:475\tacc:1.0 \t loss:0.05765239428728819\n",
      "epoch:476\tacc:1.0 \t loss:0.05732795409858227\n",
      "epoch:477\tacc:1.0 \t loss:0.05700260680168867\n",
      "epoch:478\tacc:1.0 \t loss:0.056676373817026615\n",
      "epoch:479\tacc:1.0 \t loss:0.056349088437855244\n",
      "epoch:480\tacc:1.0 \t loss:0.056020669639110565\n",
      "epoch:481\tacc:1.0 \t loss:0.05569104012101889\n",
      "epoch:482\tacc:1.0 \t loss:0.055360221303999424\n",
      "epoch:483\tacc:1.0 \t loss:0.055028134025633335\n",
      "epoch:484\tacc:1.0 \t loss:0.05469465535134077\n",
      "epoch:485\tacc:1.0 \t loss:0.05435990355908871\n",
      "epoch:486\tacc:1.0 \t loss:0.05402367375791073\n",
      "epoch:487\tacc:1.0 \t loss:0.05368605721741915\n",
      "epoch:488\tacc:1.0 \t loss:0.05334700644016266\n",
      "epoch:489\tacc:1.0 \t loss:0.05300632864236832\n",
      "epoch:490\tacc:1.0 \t loss:0.0526641383767128\n",
      "epoch:491\tacc:1.0 \t loss:0.052320439368486404\n",
      "epoch:492\tacc:1.0 \t loss:0.051975161768496037\n",
      "epoch:493\tacc:1.0 \t loss:0.05162821616977453\n",
      "epoch:494\tacc:1.0 \t loss:0.051279678009450436\n",
      "epoch:495\tacc:1.0 \t loss:0.05092955380678177\n",
      "epoch:496\tacc:1.0 \t loss:0.05057772807776928\n",
      "epoch:497\tacc:1.0 \t loss:0.05022427253425121\n",
      "epoch:498\tacc:1.0 \t loss:0.049869176000356674\n",
      "epoch:499\tacc:1.0 \t loss:0.04951251205056906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▂▁▁▁▂▂▂▃▃▃▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_loss</td><td>██▇▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>1.0</td></tr><tr><td>train_loss</td><td>0.04951</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dancing-mandu-1</strong> at: <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/3txc101t\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/3txc101t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230202_131502-3txc101t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    with wandb.init(**trial) as exp:\n",
    "        dev_dataset = WikiDataset(\n",
    "            DATASET_PATH,\n",
    "            DATASET_NAME,\n",
    "            VOCAB_PATH,\n",
    "        )\n",
    "\n",
    "        dev_dl = DataLoader(\n",
    "            dev_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=SHUFFLE,\n",
    "        )\n",
    "\n",
    "        # as it is a single batch experiment\n",
    "        batch_data = next(iter(dev_dl))\n",
    "        dev_dl = [batch_data] * STEPS_PER_EPOCH\n",
    "\n",
    "        # create model\n",
    "        model = GraphSeq(\n",
    "            emb_dim=EMB_DIM,\n",
    "            vocab_size=len(dev_dataset.entity_2_id.data),\n",
    "            pad_idx=PAD_IDX,\n",
    "            graph_conv_layers=GRAPH_CONV_LAYERS,\n",
    "            rnn_decoder_layers=RNN_LAYERS,\n",
    "            rnn_dropout=RNN_DROPOUT,\n",
    "        )\n",
    "\n",
    "        # create optimizer\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=LR,\n",
    "        )\n",
    "\n",
    "        # setup for training\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        model = model.to(DEVICE)\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            metrics = train(\n",
    "                model=model,\n",
    "                dataloader=dev_dl,\n",
    "                optimizer=optimizer,\n",
    "                steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                device=DEVICE,\n",
    "                gradient_accumulation_steps=ACCUMULATION_STEPS,\n",
    "                pad_idx=PAD_IDX,\n",
    "                max_grad_norm=MAX_GRAD_NORM,\n",
    "            )\n",
    "\n",
    "            print(\"epoch:{epoch}\\tacc:{acc} \\t loss:{loss}\".format(\n",
    "                epoch=epoch,\n",
    "                acc=metrics[\"train_accuracy\"],\n",
    "                loss=metrics[\"train_loss\"],\n",
    "            ))\n",
    "            exp.log(metrics, step=epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfbe21d3",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "As we are able to overfit a single batch, we can move to the next step\n",
    "\n",
    "*Goal*: train and eval on full dataset with simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db7cd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"graph-seq train and eval\"\n",
    "\n",
    "trials = [\n",
    "    # trial setup\n",
    "    dict(\n",
    "        job_type=\"train\",\n",
    "        project=project,\n",
    "        group=experiment_name,\n",
    "        notes=\n",
    "        \"test training and validation pipeline on the entire dataset with a simple model\",\n",
    "        config=dict(\n",
    "            dataset_base_path=\"data/wiki\",\n",
    "            train_dataset_name=\"train\",\n",
    "            dev_dataset_name=\"dev\",\n",
    "            vocab_path=\"data/wiki/entity_2_id.bin\",\n",
    "            batch_size=64,\n",
    "            learning_rate=0.001,\n",
    "            device=\"cuda\",\n",
    "            accumulation_steps=1,\n",
    "            max_grad_norm=20.,\n",
    "            epochs=10,\n",
    "            pad_idx=0,\n",
    "            emb_dim=60,\n",
    "            graph_conv_layers=3,\n",
    "            rnn_layers=1,\n",
    "            rnn_dropout=0.5,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02d6623a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ando_cavallari/astra-zeneca/wandb/run-20230202_141619-rh1ewoc8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andompesta/astrazeneca/runs/rh1ewoc8\" target=\"_blank\">brilliant-wonton-4</a></strong> to <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/rh1ewoc8\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/rh1ewoc8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:0\tacc:0.5454857950386077 \t loss:1.539299227728611\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'eval_loss': 1.034965844316916, 'eval_accuracy': 0.6678873916547657, 'eval_blue_score': 0.15293316888491967}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:1\tacc:0.707031291443073 \t loss:0.8456747814691568\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'eval_loss': 0.7425178856109128, 'eval_accuracy': 0.7442981773963209, 'eval_blue_score': 0.3130078731901078}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:2\tacc:0.7852906664629656 \t loss:0.5814311626313358\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {'eval_loss': 0.46895650616197876, 'eval_accuracy': 0.8221370699772351, 'eval_blue_score': 0.49503647616001184}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:3\tacc:0.8574517430227105 \t loss:0.3713625632945309\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 {'eval_loss': 0.31700430234724825, 'eval_accuracy': 0.8869816042871485, 'eval_blue_score': 0.6625987538994469}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:4\tacc:0.9210361590480374 \t loss:0.2205903691902469\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 {'eval_loss': 0.23028418664453607, 'eval_accuracy': 0.9112876998996083, 'eval_blue_score': 0.7245261139390683}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:5\tacc:0.9675500075326929 \t loss:0.12293462592698252\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 {'eval_loss': 0.09515526396871517, 'eval_accuracy': 0.9709429747041274, 'eval_blue_score': 0.9055122469083374}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:6\tacc:0.9907103859921618 \t loss:0.05964791111195635\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 {'eval_loss': 0.06218583085997538, 'eval_accuracy': 0.9823961087623545, 'eval_blue_score': 0.9372030192327453}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:7\tacc:0.9975025409576918 \t loss:0.028717726043020624\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 {'eval_loss': 0.03615186017740405, 'eval_accuracy': 0.990059810811193, 'eval_blue_score': 0.9657315452845179}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:8\tacc:0.9991342707822755 \t loss:0.01386546492116752\n",
      "eval batch : 50\n",
      "eval batch : 100\n",
      "8 {'eval_loss': 0.011347157714860232, 'eval_accuracy': 0.9982749600554275, 'eval_blue_score': 0.9935185956970694}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:9\tacc:0.999522575799049 \t loss:0.006710440323320212\n",
      "eval batch : 50\n",
      "eval batch : 100\n",
      "9 {'eval_loss': 0.005654219320135642, 'eval_accuracy': 0.9994202734612502, 'eval_blue_score': 0.997852666221114}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>▁▃▄▆▆▇████</td></tr><tr><td>eval_blue_score</td><td>▁▂▄▅▆▇▇███</td></tr><tr><td>eval_loss</td><td>█▆▄▃▃▂▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇█████</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>0.99942</td></tr><tr><td>eval_blue_score</td><td>0.99785</td></tr><tr><td>eval_loss</td><td>0.00565</td></tr><tr><td>train_accuracy</td><td>0.99952</td></tr><tr><td>train_loss</td><td>0.00671</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brilliant-wonton-4</strong> at: <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/rh1ewoc8\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/rh1ewoc8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230202_141619-rh1ewoc8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    with wandb.init(**trial) as exp:\n",
    "        train_dataset = WikiDataset(\n",
    "            exp.config[\"dataset_base_path\"],\n",
    "            exp.config[\"train_dataset_name\"],\n",
    "            exp.config[\"vocab_path\"],\n",
    "        )\n",
    "        train_dl = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=exp.config[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "        )\n",
    "        exp.config[\"steps_per_epoch\"] = len(train_dl)\n",
    "\n",
    "        dev_dataset = WikiDataset(\n",
    "            exp.config[\"dataset_base_path\"],\n",
    "            exp.config[\"dev_dataset_name\"],\n",
    "            exp.config[\"vocab_path\"],\n",
    "        )\n",
    "        dev_dl = DataLoader(\n",
    "            dev_dataset,\n",
    "            batch_size=exp.config[\"batch_size\"],\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # create model\n",
    "        model = GraphSeq(\n",
    "            emb_dim=exp.config[\"emb_dim\"],\n",
    "            vocab_size=len(dev_dataset.entity_2_id.data),\n",
    "            pad_idx=exp.config[\"pad_idx\"],\n",
    "            graph_conv_layers=exp.config[\"graph_conv_layers\"],\n",
    "            rnn_decoder_layers=exp.config[\"rnn_layers\"],\n",
    "            rnn_dropout=exp.config[\"rnn_dropout\"],\n",
    "        )\n",
    "\n",
    "        # create optimizer\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=exp.config[\"learning_rate\"],\n",
    "        )\n",
    "\n",
    "        device = exp.config[\"device\"]\n",
    "        # setup for training\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        model = model.to(device)\n",
    "\n",
    "        for epoch in range(exp.config[\"epochs\"]):\n",
    "\n",
    "            metrics = train(\n",
    "                model=model,\n",
    "                dataloader=dev_dl,\n",
    "                optimizer=optimizer,\n",
    "                steps_per_epoch=len(train_dl),\n",
    "                device=device,\n",
    "                gradient_accumulation_steps=exp.config[\"accumulation_steps\"],\n",
    "                pad_idx=exp.config[\"pad_idx\"],\n",
    "                max_grad_norm=exp.config[\"max_grad_norm\"],\n",
    "            )\n",
    "\n",
    "            print(\"epoch:{epoch}\\tacc:{acc} \\t loss:{loss}\".format(\n",
    "                epoch=epoch,\n",
    "                acc=metrics[\"train_accuracy\"],\n",
    "                loss=metrics[\"train_loss\"],\n",
    "            ))\n",
    "            exp.log(metrics, step=epoch)\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                # eval every 1 epochs\n",
    "                is_best = False\n",
    "                scores = eval(\n",
    "                    model=model,\n",
    "                    dataloader=dev_dl,\n",
    "                    device=device,\n",
    "                )\n",
    "\n",
    "                print(epoch, scores)\n",
    "                print()\n",
    "                exp.log(scores, step=epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1debeed81619785a8d6b1d6ab4f3be2c289b30083acd6f537a7446573ac7344f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
