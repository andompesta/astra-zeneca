{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34505f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb47ecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import nn, Tensor, optim\n",
    "from typing import Optional\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "from src.datapipe import WikiDataset\n",
    "from src.utils.common import PAD, save_checkpoint\n",
    "from src.utils.training import train_fn, eval_fn\n",
    "from src.models.graph_seq import GraphSeq, GraphSeqAttn\n",
    "from src.optim import (\n",
    "    get_optimizer,\n",
    "    get_group_params,\n",
    "    get_linear_scheduler_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606c2205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandompesta\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ando_cavallari/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"fd8e6949c75375b623a566795f8460842fee1e14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab487d48",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "*Goal* overfit a single batch to verify code correctnes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c8115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"astrazeneca\"\n",
    "experiment_name = \"single-batch\"\n",
    "\n",
    "trials = [\n",
    "    # trial setup\n",
    "    dict(\n",
    "        job_type=\"train\",\n",
    "        project=project,\n",
    "        group=experiment_name,\n",
    "        notes=\"test training pipeline with a single batch on simple model\",\n",
    "        config=dict(\n",
    "            dataset_base_path=\"data/wiki\",\n",
    "            dataset_name=\"dev\",\n",
    "            vocab_path=\"data/wiki/entity_2_id.bin\",\n",
    "            batch_size=5,\n",
    "            learning_rate=0.003,\n",
    "            device=\"cuda\",\n",
    "            accumulation_steps=1,\n",
    "            max_grad_norm=20.,\n",
    "            epochs=500,\n",
    "            steps_per_epoch=5,\n",
    "            pad_idx=0,\n",
    "            emb_dim=6,\n",
    "            graph_conv_layers=1,\n",
    "            rnn_decoder_layers=1,\n",
    "            rnn_dropout=0.,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00d8644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandompesta\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ando_cavallari/astra-zeneca/wandb/run-20230202_220212-p3mgg4jv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andompesta/astrazeneca/runs/p3mgg4jv\" target=\"_blank\">lunar-mandu-36</a></strong> to <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/p3mgg4jv\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/p3mgg4jv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\tacc:0.0 \t loss:4.331194305419922\n",
      "epoch:1\tacc:0.0 \t loss:4.308772277832031\n",
      "epoch:2\tacc:0.0 \t loss:4.278983402252197\n",
      "epoch:3\tacc:0.07647058823529412 \t loss:4.238000202178955\n",
      "epoch:4\tacc:0.15294117647058825 \t loss:4.180426597595215\n",
      "epoch:5\tacc:0.2647058823529412 \t loss:4.098905754089356\n",
      "epoch:6\tacc:0.16470588235294117 \t loss:3.985474729537964\n",
      "epoch:7\tacc:0.14705882352941177 \t loss:3.8361175537109373\n",
      "epoch:8\tacc:0.14705882352941177 \t loss:3.6525842189788817\n",
      "epoch:9\tacc:0.11176470588235295 \t loss:3.4361230373382567\n",
      "epoch:10\tacc:0.029411764705882353 \t loss:3.178119659423828\n",
      "epoch:11\tacc:0.029411764705882353 \t loss:2.8574286460876466\n",
      "epoch:12\tacc:0.07647058823529412 \t loss:2.445392942428589\n",
      "epoch:13\tacc:0.08823529411764706 \t loss:1.9586676359176636\n",
      "epoch:14\tacc:0.08823529411764706 \t loss:1.5992687702178956\n",
      "epoch:15\tacc:0.08823529411764706 \t loss:1.447387194633484\n",
      "epoch:16\tacc:0.08823529411764706 \t loss:1.3276278495788574\n",
      "epoch:17\tacc:0.14705882352941177 \t loss:1.2392212390899657\n",
      "epoch:18\tacc:0.2647058823529412 \t loss:1.1812836170196532\n",
      "epoch:19\tacc:0.2647058823529412 \t loss:1.1314882516860962\n",
      "epoch:20\tacc:0.2 \t loss:1.0901673555374145\n",
      "epoch:21\tacc:0.23529411764705882 \t loss:1.0592937469482422\n",
      "epoch:22\tacc:0.2647058823529412 \t loss:1.0330798149108886\n",
      "epoch:23\tacc:0.2647058823529412 \t loss:1.0088474869728088\n",
      "epoch:24\tacc:0.2647058823529412 \t loss:0.9874089121818542\n",
      "epoch:25\tacc:0.2529411764705882 \t loss:0.9690288186073304\n",
      "epoch:26\tacc:0.2823529411764706 \t loss:0.9538306593894958\n",
      "epoch:27\tacc:0.29411764705882354 \t loss:0.9402603387832642\n",
      "epoch:28\tacc:0.29411764705882354 \t loss:0.9263499259948731\n",
      "epoch:29\tacc:0.29411764705882354 \t loss:0.9112041473388672\n",
      "epoch:30\tacc:0.29411764705882354 \t loss:0.8947423815727233\n",
      "epoch:31\tacc:0.28823529411764703 \t loss:0.8780978083610534\n",
      "epoch:32\tacc:0.2823529411764706 \t loss:0.8652379274368286\n",
      "epoch:33\tacc:0.29411764705882354 \t loss:0.8546959400177002\n",
      "epoch:34\tacc:0.29411764705882354 \t loss:0.8451448440551758\n",
      "epoch:35\tacc:0.3058823529411765 \t loss:0.8360424399375915\n",
      "epoch:36\tacc:0.3352941176470588 \t loss:0.827038300037384\n",
      "epoch:37\tacc:0.2647058823529412 \t loss:0.8176669239997864\n",
      "epoch:38\tacc:0.2647058823529412 \t loss:0.8077186584472656\n",
      "epoch:39\tacc:0.32941176470588235 \t loss:0.7967173337936402\n",
      "epoch:40\tacc:0.43529411764705883 \t loss:0.7843163132667541\n",
      "epoch:41\tacc:0.47058823529411764 \t loss:0.7706307172775269\n",
      "epoch:42\tacc:0.47058823529411764 \t loss:0.7558815479278564\n",
      "epoch:43\tacc:0.47058823529411764 \t loss:0.7398837685585022\n",
      "epoch:44\tacc:0.47058823529411764 \t loss:0.722354257106781\n",
      "epoch:45\tacc:0.43529411764705883 \t loss:0.7034647583961486\n",
      "epoch:46\tacc:0.4176470588235294 \t loss:0.6839664936065674\n",
      "epoch:47\tacc:0.43529411764705883 \t loss:0.6644681572914124\n",
      "epoch:48\tacc:0.47058823529411764 \t loss:0.6455464243888855\n",
      "epoch:49\tacc:0.47058823529411764 \t loss:0.6274637699127197\n",
      "epoch:50\tacc:0.47058823529411764 \t loss:0.6103190183639526\n",
      "epoch:51\tacc:0.47058823529411764 \t loss:0.5942649126052857\n",
      "epoch:52\tacc:0.47058823529411764 \t loss:0.5794149756431579\n",
      "epoch:53\tacc:0.47058823529411764 \t loss:0.5656012177467347\n",
      "epoch:54\tacc:0.49411764705882355 \t loss:0.553018844127655\n",
      "epoch:55\tacc:0.5235294117647059 \t loss:0.5409350275993348\n",
      "epoch:56\tacc:0.5176470588235295 \t loss:0.529078209400177\n",
      "epoch:57\tacc:0.5588235294117647 \t loss:0.5176288843154907\n",
      "epoch:58\tacc:0.5764705882352941 \t loss:0.5060185790061951\n",
      "epoch:59\tacc:0.5882352941176471 \t loss:0.49386069774627683\n",
      "epoch:60\tacc:0.5882352941176471 \t loss:0.481010377407074\n",
      "epoch:61\tacc:0.5882352941176471 \t loss:0.4664329826831818\n",
      "epoch:62\tacc:0.5882352941176471 \t loss:0.4509709894657135\n",
      "epoch:63\tacc:0.6235294117647059 \t loss:0.4365340769290924\n",
      "epoch:64\tacc:0.6764705882352942 \t loss:0.4232334136962891\n",
      "epoch:65\tacc:0.6764705882352942 \t loss:0.4106399655342102\n",
      "epoch:66\tacc:0.6764705882352942 \t loss:0.39830942153930665\n",
      "epoch:67\tacc:0.7 \t loss:0.3863237679004669\n",
      "epoch:68\tacc:0.7058823529411765 \t loss:0.37518481612205506\n",
      "epoch:69\tacc:0.7 \t loss:0.3660529613494873\n",
      "epoch:70\tacc:0.6882352941176471 \t loss:0.3545550167560577\n",
      "epoch:71\tacc:0.711764705882353 \t loss:0.34437506198883056\n",
      "epoch:72\tacc:0.6941176470588235 \t loss:0.33419694304466246\n",
      "epoch:73\tacc:0.7058823529411765 \t loss:0.3245301127433777\n",
      "epoch:74\tacc:0.7 \t loss:0.3152895927429199\n",
      "epoch:75\tacc:0.7058823529411765 \t loss:0.30657999515533446\n",
      "epoch:76\tacc:0.7235294117647059 \t loss:0.2982837796211243\n",
      "epoch:77\tacc:0.7411764705882353 \t loss:0.2905067801475525\n",
      "epoch:78\tacc:0.7529411764705882 \t loss:0.28247185945510866\n",
      "epoch:79\tacc:0.7352941176470589 \t loss:0.2829293549060822\n",
      "epoch:80\tacc:0.7411764705882353 \t loss:0.2776672303676605\n",
      "epoch:81\tacc:0.7529411764705882 \t loss:0.26844205260276793\n",
      "epoch:82\tacc:0.7588235294117647 \t loss:0.26239065527915956\n",
      "epoch:83\tacc:0.7470588235294118 \t loss:0.256349915266037\n",
      "epoch:84\tacc:0.7647058823529411 \t loss:0.25034388303756716\n",
      "epoch:85\tacc:0.7647058823529411 \t loss:0.24519014358520508\n",
      "epoch:86\tacc:0.7647058823529411 \t loss:0.240419802069664\n",
      "epoch:87\tacc:0.7647058823529411 \t loss:0.23591820895671844\n",
      "epoch:88\tacc:0.7588235294117647 \t loss:0.2317260444164276\n",
      "epoch:89\tacc:0.7647058823529411 \t loss:0.22779124975204468\n",
      "epoch:90\tacc:0.7647058823529411 \t loss:0.22411153614521026\n",
      "epoch:91\tacc:0.7470588235294118 \t loss:0.22052255272865295\n",
      "epoch:92\tacc:0.7647058823529411 \t loss:0.21710586547851562\n",
      "epoch:93\tacc:0.7647058823529411 \t loss:0.2137924313545227\n",
      "epoch:94\tacc:0.7705882352941177 \t loss:0.2105735719203949\n",
      "epoch:95\tacc:0.7941176470588235 \t loss:0.2074243515729904\n",
      "epoch:96\tacc:0.788235294117647 \t loss:0.20456828773021699\n",
      "epoch:97\tacc:0.7470588235294118 \t loss:0.22199006676673888\n",
      "epoch:98\tacc:0.7470588235294118 \t loss:0.22047913670539857\n",
      "epoch:99\tacc:0.7705882352941177 \t loss:0.20527586936950684\n",
      "epoch:100\tacc:0.7823529411764706 \t loss:0.2019680768251419\n",
      "epoch:101\tacc:0.7823529411764706 \t loss:0.19716412127017974\n",
      "epoch:102\tacc:0.7823529411764706 \t loss:0.1930908143520355\n",
      "epoch:103\tacc:0.7941176470588235 \t loss:0.1903667390346527\n",
      "epoch:104\tacc:0.788235294117647 \t loss:0.18732019364833832\n",
      "epoch:105\tacc:0.788235294117647 \t loss:0.18497455418109893\n",
      "epoch:106\tacc:0.7941176470588235 \t loss:0.18265355825424195\n",
      "epoch:107\tacc:0.8 \t loss:0.18038270175457\n",
      "epoch:108\tacc:0.8176470588235294 \t loss:0.1782035529613495\n",
      "epoch:109\tacc:0.8235294117647058 \t loss:0.17609237432479857\n",
      "epoch:110\tacc:0.8235294117647058 \t loss:0.17402960360050201\n",
      "epoch:111\tacc:0.8235294117647058 \t loss:0.17200728952884675\n",
      "epoch:112\tacc:0.8235294117647058 \t loss:0.17002252340316773\n",
      "epoch:113\tacc:0.8235294117647058 \t loss:0.1680549681186676\n",
      "epoch:114\tacc:0.8235294117647058 \t loss:0.1661207526922226\n",
      "epoch:115\tacc:0.8235294117647058 \t loss:0.16420666873455048\n",
      "epoch:116\tacc:0.8235294117647058 \t loss:0.16231921017169954\n",
      "epoch:117\tacc:0.8235294117647058 \t loss:0.16045375168323517\n",
      "epoch:118\tacc:0.8235294117647058 \t loss:0.1586117148399353\n",
      "epoch:119\tacc:0.8235294117647058 \t loss:0.15678881406784057\n",
      "epoch:120\tacc:0.8235294117647058 \t loss:0.15498968660831453\n",
      "epoch:121\tacc:0.8235294117647058 \t loss:0.15327989757061006\n",
      "epoch:122\tacc:0.8117647058823529 \t loss:0.1731625199317932\n",
      "epoch:123\tacc:0.6882352941176471 \t loss:0.3623249024152756\n",
      "epoch:124\tacc:0.6647058823529411 \t loss:0.34159242510795595\n",
      "epoch:125\tacc:0.7529411764705882 \t loss:0.21379703879356385\n",
      "epoch:126\tacc:0.7529411764705882 \t loss:0.18764001429080962\n",
      "epoch:127\tacc:0.8117647058823529 \t loss:0.1719524681568146\n",
      "epoch:128\tacc:0.8117647058823529 \t loss:0.1634479433298111\n",
      "epoch:129\tacc:0.8294117647058824 \t loss:0.15624548494815826\n",
      "epoch:130\tacc:0.8352941176470589 \t loss:0.15240975320339203\n",
      "epoch:131\tacc:0.8352941176470589 \t loss:0.14967964291572572\n",
      "epoch:132\tacc:0.8352941176470589 \t loss:0.1472755879163742\n",
      "epoch:133\tacc:0.8235294117647058 \t loss:0.14529815018177034\n",
      "epoch:134\tacc:0.8235294117647058 \t loss:0.1437411665916443\n",
      "epoch:135\tacc:0.8235294117647058 \t loss:0.1421847462654114\n",
      "epoch:136\tacc:0.8235294117647058 \t loss:0.1408648818731308\n",
      "epoch:137\tacc:0.8176470588235294 \t loss:0.13959577679634094\n",
      "epoch:138\tacc:0.8470588235294118 \t loss:0.13838439881801606\n",
      "epoch:139\tacc:0.8529411764705882 \t loss:0.1372297704219818\n",
      "epoch:140\tacc:0.8529411764705882 \t loss:0.13610770404338837\n",
      "epoch:141\tacc:0.8529411764705882 \t loss:0.13502175211906434\n",
      "epoch:142\tacc:0.8529411764705882 \t loss:0.13395612835884094\n",
      "epoch:143\tacc:0.8529411764705882 \t loss:0.13292124271392822\n",
      "epoch:144\tacc:0.8705882352941177 \t loss:0.13190589845180511\n",
      "epoch:145\tacc:0.8529411764705882 \t loss:0.13091315627098082\n",
      "epoch:146\tacc:0.8529411764705882 \t loss:0.12994011044502257\n",
      "epoch:147\tacc:0.8529411764705882 \t loss:0.12898626625537873\n",
      "epoch:148\tacc:0.8529411764705882 \t loss:0.12804999351501464\n",
      "epoch:149\tacc:0.8529411764705882 \t loss:0.12713206112384795\n",
      "epoch:150\tacc:0.8529411764705882 \t loss:0.1262466847896576\n",
      "epoch:151\tacc:0.8588235294117647 \t loss:0.1280161291360855\n",
      "epoch:152\tacc:0.8117647058823529 \t loss:0.19220567643642425\n",
      "epoch:153\tacc:0.6647058823529411 \t loss:0.5670293390750885\n",
      "epoch:154\tacc:0.7294117647058823 \t loss:0.2643283396959305\n",
      "epoch:155\tacc:0.7058823529411765 \t loss:0.25591638386249543\n",
      "epoch:156\tacc:0.7529411764705882 \t loss:0.20797547399997712\n",
      "epoch:157\tacc:0.7764705882352941 \t loss:0.18081722259521485\n",
      "epoch:158\tacc:0.8 \t loss:0.166913765668869\n",
      "epoch:159\tacc:0.8294117647058824 \t loss:0.15690818727016448\n",
      "epoch:160\tacc:0.8352941176470589 \t loss:0.14559950530529023\n",
      "epoch:161\tacc:0.8470588235294118 \t loss:0.13753102719783783\n",
      "epoch:162\tacc:0.8529411764705882 \t loss:0.13322023153305054\n",
      "epoch:163\tacc:0.8588235294117647 \t loss:0.12846806049346923\n",
      "epoch:164\tacc:0.8647058823529412 \t loss:0.12635108232498168\n",
      "epoch:165\tacc:0.8470588235294118 \t loss:0.12465322017669678\n",
      "epoch:166\tacc:0.8588235294117647 \t loss:0.12324271649122238\n",
      "epoch:167\tacc:0.8529411764705882 \t loss:0.12193895578384399\n",
      "epoch:168\tacc:0.8529411764705882 \t loss:0.12095952928066253\n",
      "epoch:169\tacc:0.8470588235294118 \t loss:0.11996719390153884\n",
      "epoch:170\tacc:0.8529411764705882 \t loss:0.1191395416855812\n",
      "epoch:171\tacc:0.8529411764705882 \t loss:0.1183162659406662\n",
      "epoch:172\tacc:0.8529411764705882 \t loss:0.11755183935165406\n",
      "epoch:173\tacc:0.8470588235294118 \t loss:0.11681784391403198\n",
      "epoch:174\tacc:0.8529411764705882 \t loss:0.11610672771930694\n",
      "epoch:175\tacc:0.8529411764705882 \t loss:0.11541677713394165\n",
      "epoch:176\tacc:0.8529411764705882 \t loss:0.11474387794733047\n",
      "epoch:177\tacc:0.8529411764705882 \t loss:0.11408708542585373\n",
      "epoch:178\tacc:0.8529411764705882 \t loss:0.1134444683790207\n",
      "epoch:179\tacc:0.8529411764705882 \t loss:0.11281519830226898\n",
      "epoch:180\tacc:0.8529411764705882 \t loss:0.11219770610332488\n",
      "epoch:181\tacc:0.8529411764705882 \t loss:0.11159219145774842\n",
      "epoch:182\tacc:0.8529411764705882 \t loss:0.110997873544693\n",
      "epoch:183\tacc:0.8529411764705882 \t loss:0.1104146733880043\n",
      "epoch:184\tacc:0.8529411764705882 \t loss:0.10984248369932174\n",
      "epoch:185\tacc:0.8529411764705882 \t loss:0.10928117483854294\n",
      "epoch:186\tacc:0.8529411764705882 \t loss:0.10873058587312698\n",
      "epoch:187\tacc:0.8529411764705882 \t loss:0.10819080471992493\n",
      "epoch:188\tacc:0.8529411764705882 \t loss:0.10766175240278245\n",
      "epoch:189\tacc:0.8529411764705882 \t loss:0.10713898688554764\n",
      "epoch:190\tacc:0.8529411764705882 \t loss:0.10661621242761612\n",
      "epoch:191\tacc:0.8529411764705882 \t loss:0.10609696060419083\n",
      "epoch:192\tacc:0.8529411764705882 \t loss:0.10557684898376465\n",
      "epoch:193\tacc:0.8529411764705882 \t loss:0.10507936626672745\n",
      "epoch:194\tacc:0.8588235294117647 \t loss:0.10729490816593171\n",
      "epoch:195\tacc:0.8352941176470589 \t loss:0.13854551464319229\n",
      "epoch:196\tacc:0.8235294117647058 \t loss:0.16976883113384247\n",
      "epoch:197\tacc:0.7823529411764706 \t loss:0.3238678127527237\n",
      "epoch:198\tacc:0.7764705882352941 \t loss:0.22154990285634996\n",
      "epoch:199\tacc:0.8058823529411765 \t loss:0.17952737659215928\n",
      "epoch:200\tacc:0.7941176470588235 \t loss:0.24310367405414582\n",
      "epoch:201\tacc:0.8176470588235294 \t loss:0.14358292818069457\n",
      "epoch:202\tacc:0.8529411764705882 \t loss:0.12783143371343614\n",
      "epoch:203\tacc:0.8588235294117647 \t loss:0.11632189005613328\n",
      "epoch:204\tacc:0.8588235294117647 \t loss:0.11214667409658433\n",
      "epoch:205\tacc:0.8529411764705882 \t loss:0.10957226157188416\n",
      "epoch:206\tacc:0.8588235294117647 \t loss:0.10747478604316711\n",
      "epoch:207\tacc:0.8529411764705882 \t loss:0.10586091578006744\n",
      "epoch:208\tacc:0.8529411764705882 \t loss:0.1044322669506073\n",
      "epoch:209\tacc:0.8529411764705882 \t loss:0.10357252061367035\n",
      "epoch:210\tacc:0.8529411764705882 \t loss:0.1025951012969017\n",
      "epoch:211\tacc:0.8529411764705882 \t loss:0.10205481797456742\n",
      "epoch:212\tacc:0.8529411764705882 \t loss:0.10147561281919479\n",
      "epoch:213\tacc:0.8529411764705882 \t loss:0.10099582970142365\n",
      "epoch:214\tacc:0.8529411764705882 \t loss:0.10056361854076386\n",
      "epoch:215\tacc:0.8529411764705882 \t loss:0.10014103651046753\n",
      "epoch:216\tacc:0.8529411764705882 \t loss:0.09975406229496002\n",
      "epoch:217\tacc:0.8529411764705882 \t loss:0.09938192814588546\n",
      "epoch:218\tacc:0.8470588235294118 \t loss:0.09902976155281067\n",
      "epoch:219\tacc:0.8470588235294118 \t loss:0.09868929982185363\n",
      "epoch:220\tacc:0.8529411764705882 \t loss:0.09836204051971435\n",
      "epoch:221\tacc:0.8529411764705882 \t loss:0.09804528355598449\n",
      "epoch:222\tacc:0.8529411764705882 \t loss:0.09773869663476945\n",
      "epoch:223\tacc:0.8470588235294118 \t loss:0.0974453404545784\n",
      "epoch:224\tacc:0.8529411764705882 \t loss:0.09716023355722428\n",
      "epoch:225\tacc:0.8411764705882353 \t loss:0.09688165932893752\n",
      "epoch:226\tacc:0.8470588235294118 \t loss:0.09660973399877548\n",
      "epoch:227\tacc:0.8529411764705882 \t loss:0.0963455468416214\n",
      "epoch:228\tacc:0.8470588235294118 \t loss:0.09608692526817322\n",
      "epoch:229\tacc:0.8411764705882353 \t loss:0.09583445787429809\n",
      "epoch:230\tacc:0.8529411764705882 \t loss:0.095587620139122\n",
      "epoch:231\tacc:0.8470588235294118 \t loss:0.09534598141908646\n",
      "epoch:232\tacc:0.8411764705882353 \t loss:0.09510935842990875\n",
      "epoch:233\tacc:0.8529411764705882 \t loss:0.0948776826262474\n",
      "epoch:234\tacc:0.8529411764705882 \t loss:0.09465057849884033\n",
      "epoch:235\tacc:0.8529411764705882 \t loss:0.09442794322967529\n",
      "epoch:236\tacc:0.8529411764705882 \t loss:0.09420960247516633\n",
      "epoch:237\tacc:0.8529411764705882 \t loss:0.09399523735046386\n",
      "epoch:238\tacc:0.8529411764705882 \t loss:0.09378490895032883\n",
      "epoch:239\tacc:0.8529411764705882 \t loss:0.09357835650444031\n",
      "epoch:240\tacc:0.8529411764705882 \t loss:0.0933754026889801\n",
      "epoch:241\tacc:0.8529411764705882 \t loss:0.0931758850812912\n",
      "epoch:242\tacc:0.8529411764705882 \t loss:0.09297984689474106\n",
      "epoch:243\tacc:0.8529411764705882 \t loss:0.09278687685728074\n",
      "epoch:244\tacc:0.8529411764705882 \t loss:0.0925971359014511\n",
      "epoch:245\tacc:0.8529411764705882 \t loss:0.09241028428077698\n",
      "epoch:246\tacc:0.8529411764705882 \t loss:0.09222623556852341\n",
      "epoch:247\tacc:0.8529411764705882 \t loss:0.09204498380422592\n",
      "epoch:248\tacc:0.8529411764705882 \t loss:0.09186637252569199\n",
      "epoch:249\tacc:0.8529411764705882 \t loss:0.09169039279222488\n",
      "epoch:250\tacc:0.8529411764705882 \t loss:0.09151955842971801\n",
      "epoch:251\tacc:0.8470588235294118 \t loss:0.09148844480514526\n",
      "epoch:252\tacc:0.8588235294117647 \t loss:0.10530442893505096\n",
      "epoch:253\tacc:0.8529411764705882 \t loss:0.12685247957706453\n",
      "epoch:254\tacc:0.788235294117647 \t loss:0.32460732460021974\n",
      "epoch:255\tacc:0.788235294117647 \t loss:0.4516753345727921\n",
      "epoch:256\tacc:0.8352941176470589 \t loss:0.19501169472932817\n",
      "epoch:257\tacc:0.8470588235294118 \t loss:0.13751141279935836\n",
      "epoch:258\tacc:0.8764705882352941 \t loss:0.10286678224802018\n",
      "epoch:259\tacc:0.8705882352941177 \t loss:0.09944876283407211\n",
      "epoch:260\tacc:0.8705882352941177 \t loss:0.09677995890378951\n",
      "epoch:261\tacc:0.8705882352941177 \t loss:0.09444975852966309\n",
      "epoch:262\tacc:0.8647058823529412 \t loss:0.09362919926643372\n",
      "epoch:263\tacc:0.8705882352941177 \t loss:0.09386178255081176\n",
      "epoch:264\tacc:0.8764705882352941 \t loss:0.09267111867666245\n",
      "epoch:265\tacc:0.8764705882352941 \t loss:0.0926702857017517\n",
      "epoch:266\tacc:0.8823529411764706 \t loss:0.09226246029138566\n",
      "epoch:267\tacc:0.888235294117647 \t loss:0.0919590100646019\n",
      "epoch:268\tacc:0.8823529411764706 \t loss:0.0915725976228714\n",
      "epoch:269\tacc:0.8823529411764706 \t loss:0.09152913242578506\n",
      "epoch:270\tacc:0.8823529411764706 \t loss:0.09110786318778992\n",
      "epoch:271\tacc:0.8823529411764706 \t loss:0.090933558344841\n",
      "epoch:272\tacc:0.8764705882352941 \t loss:0.09059837311506272\n",
      "epoch:273\tacc:0.8823529411764706 \t loss:0.09048559069633484\n",
      "epoch:274\tacc:0.8764705882352941 \t loss:0.09015835076570511\n",
      "epoch:275\tacc:0.8764705882352941 \t loss:0.0899370864033699\n",
      "epoch:276\tacc:0.8764705882352941 \t loss:0.08961928784847259\n",
      "epoch:277\tacc:0.8764705882352941 \t loss:0.0894487515091896\n",
      "epoch:278\tacc:0.8705882352941177 \t loss:0.08913672268390656\n",
      "epoch:279\tacc:0.8647058823529412 \t loss:0.08891802430152893\n",
      "epoch:280\tacc:0.8705882352941177 \t loss:0.08861713409423828\n",
      "epoch:281\tacc:0.8705882352941177 \t loss:0.0883894756436348\n",
      "epoch:282\tacc:0.8647058823529412 \t loss:0.08814151585102081\n",
      "epoch:283\tacc:0.8529411764705882 \t loss:0.08791548013687134\n",
      "epoch:284\tacc:0.8647058823529412 \t loss:0.08772128075361252\n",
      "epoch:285\tacc:0.8588235294117647 \t loss:0.08752200454473495\n",
      "epoch:286\tacc:0.8470588235294118 \t loss:0.08734231740236283\n",
      "epoch:287\tacc:0.8647058823529412 \t loss:0.0871622920036316\n",
      "epoch:288\tacc:0.8588235294117647 \t loss:0.08698220700025558\n",
      "epoch:289\tacc:0.8588235294117647 \t loss:0.0868037685751915\n",
      "epoch:290\tacc:0.8647058823529412 \t loss:0.08662566244602203\n",
      "epoch:291\tacc:0.8764705882352941 \t loss:0.08644701540470123\n",
      "epoch:292\tacc:0.8823529411764706 \t loss:0.08626710623502731\n",
      "epoch:293\tacc:0.8823529411764706 \t loss:0.08608554899692536\n",
      "epoch:294\tacc:0.8823529411764706 \t loss:0.08590191304683685\n",
      "epoch:295\tacc:0.8823529411764706 \t loss:0.08571585714817047\n",
      "epoch:296\tacc:0.8823529411764706 \t loss:0.08552707880735397\n",
      "epoch:297\tacc:0.888235294117647 \t loss:0.08533525466918945\n",
      "epoch:298\tacc:0.9117647058823529 \t loss:0.08514018505811691\n",
      "epoch:299\tacc:0.9117647058823529 \t loss:0.08494168519973755\n",
      "epoch:300\tacc:0.9117647058823529 \t loss:0.08473958522081375\n",
      "epoch:301\tacc:0.9117647058823529 \t loss:0.08453374952077866\n",
      "epoch:302\tacc:0.9117647058823529 \t loss:0.08432410657405853\n",
      "epoch:303\tacc:0.9117647058823529 \t loss:0.08411060720682144\n",
      "epoch:304\tacc:0.9117647058823529 \t loss:0.08389323204755783\n",
      "epoch:305\tacc:0.9117647058823529 \t loss:0.0836719423532486\n",
      "epoch:306\tacc:0.9117647058823529 \t loss:0.08344687968492508\n",
      "epoch:307\tacc:0.9117647058823529 \t loss:0.08321806788444519\n",
      "epoch:308\tacc:0.9117647058823529 \t loss:0.08298550993204117\n",
      "epoch:309\tacc:0.9117647058823529 \t loss:0.08274941593408584\n",
      "epoch:310\tacc:0.9117647058823529 \t loss:0.08250999748706818\n",
      "epoch:311\tacc:0.9117647058823529 \t loss:0.08226734399795532\n",
      "epoch:312\tacc:0.9117647058823529 \t loss:0.08202169984579086\n",
      "epoch:313\tacc:0.9117647058823529 \t loss:0.08177322298288345\n",
      "epoch:314\tacc:0.9117647058823529 \t loss:0.08152225315570831\n",
      "epoch:315\tacc:0.9117647058823529 \t loss:0.08126890510320664\n",
      "epoch:316\tacc:0.9117647058823529 \t loss:0.08101356774568558\n",
      "epoch:317\tacc:0.9117647058823529 \t loss:0.08075642585754395\n",
      "epoch:318\tacc:0.9117647058823529 \t loss:0.08049776703119278\n",
      "epoch:319\tacc:0.9117647058823529 \t loss:0.08023779243230819\n",
      "epoch:320\tacc:0.9117647058823529 \t loss:0.07997686862945556\n",
      "epoch:321\tacc:0.9117647058823529 \t loss:0.07971521914005279\n",
      "epoch:322\tacc:0.9117647058823529 \t loss:0.07945305556058883\n",
      "epoch:323\tacc:0.9117647058823529 \t loss:0.07919072061777115\n",
      "epoch:324\tacc:0.9117647058823529 \t loss:0.07892844378948212\n",
      "epoch:325\tacc:0.9117647058823529 \t loss:0.07866648733615875\n",
      "epoch:326\tacc:0.9117647058823529 \t loss:0.07840508371591567\n",
      "epoch:327\tacc:0.9117647058823529 \t loss:0.07814451158046723\n",
      "epoch:328\tacc:0.9117647058823529 \t loss:0.07788510024547576\n",
      "epoch:329\tacc:0.9117647058823529 \t loss:0.07762702256441116\n",
      "epoch:330\tacc:0.9117647058823529 \t loss:0.07737056165933609\n",
      "epoch:331\tacc:0.9117647058823529 \t loss:0.07711594551801682\n",
      "epoch:332\tacc:0.9117647058823529 \t loss:0.07686340808868408\n",
      "epoch:333\tacc:0.9117647058823529 \t loss:0.07661325484514236\n",
      "epoch:334\tacc:0.9117647058823529 \t loss:0.07636564373970031\n",
      "epoch:335\tacc:0.9117647058823529 \t loss:0.07612081915140152\n",
      "epoch:336\tacc:0.9117647058823529 \t loss:0.07587898522615433\n",
      "epoch:337\tacc:0.9117647058823529 \t loss:0.07564027905464173\n",
      "epoch:338\tacc:0.9117647058823529 \t loss:0.07540498673915863\n",
      "epoch:339\tacc:0.9117647058823529 \t loss:0.07517347782850266\n",
      "epoch:340\tacc:0.9117647058823529 \t loss:0.07494701147079467\n",
      "epoch:341\tacc:0.9117647058823529 \t loss:0.07473291605710983\n",
      "epoch:342\tacc:0.9058823529411765 \t loss:0.07467706203460693\n",
      "epoch:343\tacc:0.7529411764705882 \t loss:0.6612492829561234\n",
      "epoch:344\tacc:0.7823529411764706 \t loss:0.37692990899086\n",
      "epoch:345\tacc:0.7941176470588235 \t loss:0.22330354154109955\n",
      "epoch:346\tacc:0.711764705882353 \t loss:1.1153078481554985\n",
      "epoch:347\tacc:0.5 \t loss:2.4523832380771635\n",
      "epoch:348\tacc:0.4411764705882353 \t loss:2.6617550432682036\n",
      "epoch:349\tacc:0.5588235294117647 \t loss:0.9769707262516022\n",
      "epoch:350\tacc:0.6705882352941176 \t loss:0.5534317582845688\n",
      "epoch:351\tacc:0.8352941176470589 \t loss:0.13584192991256713\n",
      "epoch:352\tacc:0.8411764705882353 \t loss:0.13135118335485457\n",
      "epoch:353\tacc:0.8176470588235294 \t loss:0.19478853642940522\n",
      "epoch:354\tacc:0.7588235294117647 \t loss:0.2986357793211937\n",
      "epoch:355\tacc:0.8411764705882353 \t loss:0.12724915891885757\n",
      "epoch:356\tacc:0.8647058823529412 \t loss:0.11033739745616913\n",
      "epoch:357\tacc:0.8823529411764706 \t loss:0.0988046869635582\n",
      "epoch:358\tacc:0.8823529411764706 \t loss:0.10262187868356705\n",
      "epoch:359\tacc:0.9058823529411765 \t loss:0.09510236829519272\n",
      "epoch:360\tacc:0.8941176470588236 \t loss:0.08915695995092392\n",
      "epoch:361\tacc:0.9117647058823529 \t loss:0.08083778768777847\n",
      "epoch:362\tacc:0.9117647058823529 \t loss:0.07825770527124405\n",
      "epoch:363\tacc:0.9117647058823529 \t loss:0.07657968401908874\n",
      "epoch:364\tacc:0.9117647058823529 \t loss:0.07568318992853165\n",
      "epoch:365\tacc:0.9117647058823529 \t loss:0.07511904090642929\n",
      "epoch:366\tacc:0.9117647058823529 \t loss:0.07469400316476822\n",
      "epoch:367\tacc:0.9117647058823529 \t loss:0.07432635575532913\n",
      "epoch:368\tacc:0.9117647058823529 \t loss:0.07409078776836395\n",
      "epoch:369\tacc:0.9117647058823529 \t loss:0.0738537609577179\n",
      "epoch:370\tacc:0.9117647058823529 \t loss:0.07366468012332916\n",
      "epoch:371\tacc:0.9117647058823529 \t loss:0.07349158078432083\n",
      "epoch:372\tacc:0.9117647058823529 \t loss:0.0733283206820488\n",
      "epoch:373\tacc:0.9117647058823529 \t loss:0.07317476123571395\n",
      "epoch:374\tacc:0.9117647058823529 \t loss:0.07302801907062531\n",
      "epoch:375\tacc:0.9117647058823529 \t loss:0.07288868129253387\n",
      "epoch:376\tacc:0.9117647058823529 \t loss:0.07275358587503433\n",
      "epoch:377\tacc:0.9117647058823529 \t loss:0.07262329161167144\n",
      "epoch:378\tacc:0.9117647058823529 \t loss:0.07249666899442672\n",
      "epoch:379\tacc:0.9117647058823529 \t loss:0.07237372845411301\n",
      "epoch:380\tacc:0.9117647058823529 \t loss:0.07225392758846283\n",
      "epoch:381\tacc:0.9117647058823529 \t loss:0.07213714867830276\n",
      "epoch:382\tacc:0.9117647058823529 \t loss:0.07202320247888565\n",
      "epoch:383\tacc:0.9117647058823529 \t loss:0.07191187292337417\n",
      "epoch:384\tacc:0.9117647058823529 \t loss:0.07180313616991044\n",
      "epoch:385\tacc:0.9117647058823529 \t loss:0.07169688642024993\n",
      "epoch:386\tacc:0.9117647058823529 \t loss:0.07159297466278076\n",
      "epoch:387\tacc:0.9117647058823529 \t loss:0.07149144113063813\n",
      "epoch:388\tacc:0.9117647058823529 \t loss:0.07139213234186173\n",
      "epoch:389\tacc:0.9117647058823529 \t loss:0.07129501849412918\n",
      "epoch:390\tacc:0.9117647058823529 \t loss:0.071200031042099\n",
      "epoch:391\tacc:0.9117647058823529 \t loss:0.0711071252822876\n",
      "epoch:392\tacc:0.9117647058823529 \t loss:0.07101623713970184\n",
      "epoch:393\tacc:0.9117647058823529 \t loss:0.07092731595039367\n",
      "epoch:394\tacc:0.9117647058823529 \t loss:0.07084032595157623\n",
      "epoch:395\tacc:0.9117647058823529 \t loss:0.07075517028570175\n",
      "epoch:396\tacc:0.9117647058823529 \t loss:0.07067185491323472\n",
      "epoch:397\tacc:0.9117647058823529 \t loss:0.07059032320976258\n",
      "epoch:398\tacc:0.9117647058823529 \t loss:0.07051051557064056\n",
      "epoch:399\tacc:0.9117647058823529 \t loss:0.0704324021935463\n",
      "epoch:400\tacc:0.9117647058823529 \t loss:0.07035590857267379\n",
      "epoch:401\tacc:0.9117647058823529 \t loss:0.07028103470802308\n",
      "epoch:402\tacc:0.9117647058823529 \t loss:0.07020771205425262\n",
      "epoch:403\tacc:0.9117647058823529 \t loss:0.0701359525322914\n",
      "epoch:404\tacc:0.9117647058823529 \t loss:0.07006562948226928\n",
      "epoch:405\tacc:0.9117647058823529 \t loss:0.06999677866697311\n",
      "epoch:406\tacc:0.9117647058823529 \t loss:0.0699293076992035\n",
      "epoch:407\tacc:0.9117647058823529 \t loss:0.06986327022314072\n",
      "epoch:408\tacc:0.9117647058823529 \t loss:0.0697985589504242\n",
      "epoch:409\tacc:0.9117647058823529 \t loss:0.06973514109849929\n",
      "epoch:410\tacc:0.9117647058823529 \t loss:0.06967301070690154\n",
      "epoch:411\tacc:0.9117647058823529 \t loss:0.06961213648319245\n",
      "epoch:412\tacc:0.9 \t loss:0.06955246329307556\n",
      "epoch:413\tacc:0.9 \t loss:0.06949400454759598\n",
      "epoch:414\tacc:0.9117647058823529 \t loss:0.06943669021129609\n",
      "epoch:415\tacc:0.9117647058823529 \t loss:0.06938050091266632\n",
      "epoch:416\tacc:0.9117647058823529 \t loss:0.06932541728019714\n",
      "epoch:417\tacc:0.9117647058823529 \t loss:0.0692714124917984\n",
      "epoch:418\tacc:0.9117647058823529 \t loss:0.06921846568584442\n",
      "epoch:419\tacc:0.9117647058823529 \t loss:0.069166499376297\n",
      "epoch:420\tacc:0.9117647058823529 \t loss:0.06911561042070388\n",
      "epoch:421\tacc:0.9117647058823529 \t loss:0.0690656304359436\n",
      "epoch:422\tacc:0.9117647058823529 \t loss:0.06901664584875107\n",
      "epoch:423\tacc:0.9117647058823529 \t loss:0.06896856874227524\n",
      "epoch:424\tacc:0.9117647058823529 \t loss:0.0689213976264\n",
      "epoch:425\tacc:0.9117647058823529 \t loss:0.06887515932321549\n",
      "epoch:426\tacc:0.9117647058823529 \t loss:0.06882973313331604\n",
      "epoch:427\tacc:0.9117647058823529 \t loss:0.0687851920723915\n",
      "epoch:428\tacc:0.9117647058823529 \t loss:0.06874147355556488\n",
      "epoch:429\tacc:0.9117647058823529 \t loss:0.06869851797819138\n",
      "epoch:430\tacc:0.9117647058823529 \t loss:0.06865641325712205\n",
      "epoch:431\tacc:0.9117647058823529 \t loss:0.06861503720283509\n",
      "epoch:432\tacc:0.9117647058823529 \t loss:0.06857442557811737\n",
      "epoch:433\tacc:0.9117647058823529 \t loss:0.06853456348180771\n",
      "epoch:434\tacc:0.9117647058823529 \t loss:0.0684953823685646\n",
      "epoch:435\tacc:0.9117647058823529 \t loss:0.06845694780349731\n",
      "epoch:436\tacc:0.9117647058823529 \t loss:0.06841916292905807\n",
      "epoch:437\tacc:0.9117647058823529 \t loss:0.06838205456733704\n",
      "epoch:438\tacc:0.9117647058823529 \t loss:0.06834561377763748\n",
      "epoch:439\tacc:0.9117647058823529 \t loss:0.06830981820821762\n",
      "epoch:440\tacc:0.9117647058823529 \t loss:0.06827464550733567\n",
      "epoch:441\tacc:0.9117647058823529 \t loss:0.06824007779359817\n",
      "epoch:442\tacc:0.9117647058823529 \t loss:0.06820613145828247\n",
      "epoch:443\tacc:0.9117647058823529 \t loss:0.06817272752523422\n",
      "epoch:444\tacc:0.9117647058823529 \t loss:0.06813990771770477\n",
      "epoch:445\tacc:0.9117647058823529 \t loss:0.06810766905546188\n",
      "epoch:446\tacc:0.9117647058823529 \t loss:0.06807592660188674\n",
      "epoch:447\tacc:0.9117647058823529 \t loss:0.06804477721452713\n",
      "epoch:448\tacc:0.9117647058823529 \t loss:0.06801414787769318\n",
      "epoch:449\tacc:0.9117647058823529 \t loss:0.06798398196697235\n",
      "epoch:450\tacc:0.9117647058823529 \t loss:0.06795435696840287\n",
      "epoch:451\tacc:0.9117647058823529 \t loss:0.06792520880699157\n",
      "epoch:452\tacc:0.9117647058823529 \t loss:0.06789653897285461\n",
      "epoch:453\tacc:0.9117647058823529 \t loss:0.06786834001541138\n",
      "epoch:454\tacc:0.9117647058823529 \t loss:0.0678406074643135\n",
      "epoch:455\tacc:0.9117647058823529 \t loss:0.06781331896781921\n",
      "epoch:456\tacc:0.9117647058823529 \t loss:0.06778647154569625\n",
      "epoch:457\tacc:0.9117647058823529 \t loss:0.0677600309252739\n",
      "epoch:458\tacc:0.9117647058823529 \t loss:0.06773405373096467\n",
      "epoch:459\tacc:0.9117647058823529 \t loss:0.06770843267440796\n",
      "epoch:460\tacc:0.9117647058823529 \t loss:0.06768325716257095\n",
      "epoch:461\tacc:0.9117647058823529 \t loss:0.0676584541797638\n",
      "epoch:462\tacc:0.9117647058823529 \t loss:0.0676340714097023\n",
      "epoch:463\tacc:0.9117647058823529 \t loss:0.06761002093553543\n",
      "epoch:464\tacc:0.9117647058823529 \t loss:0.06758636385202407\n",
      "epoch:465\tacc:0.9117647058823529 \t loss:0.06756308227777481\n",
      "epoch:466\tacc:0.9117647058823529 \t loss:0.067540143430233\n",
      "epoch:467\tacc:0.9117647058823529 \t loss:0.06751753687858582\n",
      "epoch:468\tacc:0.9117647058823529 \t loss:0.06749527901411057\n",
      "epoch:469\tacc:0.9117647058823529 \t loss:0.06747335493564606\n",
      "epoch:470\tacc:0.9117647058823529 \t loss:0.06745176315307617\n",
      "epoch:471\tacc:0.9117647058823529 \t loss:0.06743046641349792\n",
      "epoch:472\tacc:0.9117647058823529 \t loss:0.06740953326225281\n",
      "epoch:473\tacc:0.9117647058823529 \t loss:0.06738886833190919\n",
      "epoch:474\tacc:0.9117647058823529 \t loss:0.06736850440502166\n",
      "epoch:475\tacc:0.9117647058823529 \t loss:0.06734846383333207\n",
      "epoch:476\tacc:0.9117647058823529 \t loss:0.06732869297266006\n",
      "epoch:477\tacc:0.9117647058823529 \t loss:0.0673092022538185\n",
      "epoch:478\tacc:0.9117647058823529 \t loss:0.06728998422622681\n",
      "epoch:479\tacc:0.9117647058823529 \t loss:0.06727104932069779\n",
      "epoch:480\tacc:0.9117647058823529 \t loss:0.06725243031978607\n",
      "epoch:481\tacc:0.9117647058823529 \t loss:0.06723403483629227\n",
      "epoch:482\tacc:0.9117647058823529 \t loss:0.06721586436033249\n",
      "epoch:483\tacc:0.9117647058823529 \t loss:0.06719799488782882\n",
      "epoch:484\tacc:0.9117647058823529 \t loss:0.06718032658100129\n",
      "epoch:485\tacc:0.9117647058823529 \t loss:0.06716293096542358\n",
      "epoch:486\tacc:0.9117647058823529 \t loss:0.06714577972888947\n",
      "epoch:487\tacc:0.9117647058823529 \t loss:0.06712885349988937\n",
      "epoch:488\tacc:0.9117647058823529 \t loss:0.06711214482784271\n",
      "epoch:489\tacc:0.9117647058823529 \t loss:0.06709565222263336\n",
      "epoch:490\tacc:0.9117647058823529 \t loss:0.06707940846681595\n",
      "epoch:491\tacc:0.9117647058823529 \t loss:0.06706335693597794\n",
      "epoch:492\tacc:0.9117647058823529 \t loss:0.06704755127429962\n",
      "epoch:493\tacc:0.9117647058823529 \t loss:0.0670318841934204\n",
      "epoch:494\tacc:0.9117647058823529 \t loss:0.06701650321483613\n",
      "epoch:495\tacc:0.9117647058823529 \t loss:0.06700126677751542\n",
      "epoch:496\tacc:0.9117647058823529 \t loss:0.06698624789714813\n",
      "epoch:497\tacc:0.9117647058823529 \t loss:0.06697141826152801\n",
      "epoch:498\tacc:0.9117647058823529 \t loss:0.06695677638053894\n",
      "epoch:499\tacc:0.9117647058823529 \t loss:0.06694227904081344\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▃▃▄▆▇▇▇▇▇█▆████▇▇█▇██████▇████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.91176</td></tr><tr><td>train_loss</td><td>0.06694</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-mandu-36</strong> at: <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/p3mgg4jv\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/p3mgg4jv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230202_220212-p3mgg4jv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    with wandb.init(**trial) as exp:\n",
    "        dev_dataset = WikiDataset(\n",
    "            exp.config.dataset_base_path,\n",
    "            exp.config.dataset_name,\n",
    "            exp.config.vocab_path,\n",
    "        )\n",
    "        exp.config[\"vocab_size\"] = len(dev_dataset.entity_2_id.data)\n",
    "\n",
    "        dev_dl = DataLoader(\n",
    "            dev_dataset,\n",
    "            batch_size=exp.config.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # as it is a single batch experiment\n",
    "        batch_data = next(iter(dev_dl))\n",
    "        dev_dl = [batch_data] * exp.config.steps_per_epoch\n",
    "\n",
    "        # create model\n",
    "        model = GraphSeq(\n",
    "            emb_dim=exp.config.emb_dim,\n",
    "            vocab_size=exp.config.vocab_size,\n",
    "            pad_idx=exp.config.pad_idx,\n",
    "            graph_conv_layers=exp.config.graph_conv_layers,\n",
    "            rnn_decoder_layers=exp.config.rnn_decoder_layers,\n",
    "            rnn_dropout=exp.config.rnn_dropout,\n",
    "        )\n",
    "\n",
    "        # create optimizer\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=exp.config.learning_rate,\n",
    "        )\n",
    "\n",
    "        # setup for training\n",
    "        device = exp.config.device\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        model = model.to(device)\n",
    "\n",
    "        for epoch in range(exp.config.epochs):\n",
    "\n",
    "            metrics = train_fn(\n",
    "                model=model,\n",
    "                dataloader=dev_dl,\n",
    "                optimizer=optimizer,\n",
    "                steps_per_epoch=exp.config.steps_per_epoch,\n",
    "                device=device,\n",
    "                gradient_accumulation_steps=exp.config.accumulation_steps,\n",
    "                pad_idx=exp.config.pad_idx,\n",
    "                max_grad_norm=exp.config.max_grad_norm,\n",
    "            )\n",
    "\n",
    "            print(\"epoch:{epoch}\\tacc:{acc} \\t loss:{loss}\".format(\n",
    "                epoch=epoch,\n",
    "                acc=metrics[\"train_accuracy\"],\n",
    "                loss=metrics[\"train_loss\"],\n",
    "            ))\n",
    "            exp.log(metrics, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7563ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    4,    40,     6,    34,     3,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2],\n",
       "         [    4,    17,    34,     6,    35,   227,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2],\n",
       "         [    4,    34,     6,    35,   681,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2],\n",
       "         [    4,    42,     6,    35,   227,     2,     2,     2,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2],\n",
       "         [    4,    42,     6,     6,   681,     5,     5, 14416,     2,     2,\n",
       "              2,     2,     2,     2,     2,     2,     2]], device='cuda:0'),\n",
       " tensor([[    4,    40,     6,    34,     3,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    17,    34,     6,    35,   227,     2,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    34,     6,    35,   681,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    42,     6,    35,  1061,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    42,     6,    40,  5271,     5,    37, 14416,     2,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]], device='cuda:0'),\n",
       " tensor([[    1,     4,    40,     6,    34,     3,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    17,    34,     6,    35,   227,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    34,     6,    35,   681,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    42,     6,    35,  1061,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    42,     6,    40,  5271,     5,    37, 14416,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize predictions\n",
    "logits = model(\n",
    "    batch_data.x,\n",
    "    batch_data.src_seq,\n",
    "    batch_data.edge_index,\n",
    "    batch_data.bw_edge_index,\n",
    "    batch_data.batch,\n",
    ")\n",
    "\n",
    "preds = logits.softmax(-1).argmax(-1)\n",
    "preds, batch_data.trg_seq, batch_data.src_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe21d3",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "As we are able to overfit a single batch, we can move to the next step\n",
    "\n",
    "*Goal*: train and eval on full dataset with simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db7cd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"graph-seq train and eval\"\n",
    "\n",
    "trials = [\n",
    "    # trial setup\n",
    "    dict(\n",
    "        job_type=\"train\",\n",
    "        project=project,\n",
    "        group=experiment_name,\n",
    "        notes=\n",
    "        \"test training and validation pipeline on the entire dataset with a simple model\",\n",
    "        config=dict(\n",
    "            dataset_base_path=\"data/wiki\",\n",
    "            train_dataset_name=\"train\",\n",
    "            dev_dataset_name=\"dev\",\n",
    "            vocab_path=\"data/wiki/entity_2_id.bin\",\n",
    "            batch_size=64,\n",
    "            learning_rate=0.003,\n",
    "            device=\"cuda\",\n",
    "            accumulation_steps=1,\n",
    "            max_grad_norm=20.,\n",
    "            epochs=10,\n",
    "            pad_idx=0,\n",
    "            emb_dim=60,\n",
    "            graph_conv_layers=3,\n",
    "            rnn_layers=2,\n",
    "            rnn_dropout=0.5,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d6623a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ando_cavallari/astra-zeneca/wandb/run-20230202_164907-0hbwi35f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andompesta/astrazeneca/runs/0hbwi35f\" target=\"_blank\">beaming-envelope-15</a></strong> to <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/0hbwi35f\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/0hbwi35f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:0\tacc:0.46205942798218075 \t loss:1.4920014627404705\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'eval_loss': 0.9521422697739168, 'eval_accuracy': 0.5877499919745754, 'eval_blue_score': 0.10205085511420839}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:1\tacc:0.5806792801952503 \t loss:0.9575620880191903\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'eval_loss': 0.7148003117604689, 'eval_accuracy': 0.6526435748451093, 'eval_blue_score': 0.1839454358009507}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:2\tacc:0.6296894161524803 \t loss:0.7839474743327272\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {'eval_loss': 0.5599505885532408, 'eval_accuracy': 0.7111810214760361, 'eval_blue_score': 0.2717121205156288}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:3\tacc:0.6715583642728589 \t loss:0.6657895584517792\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 {'eval_loss': 0.4461886298024293, 'eval_accuracy': 0.7669416712144073, 'eval_blue_score': 0.38070674969269325}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:4\tacc:0.703831040074014 \t loss:0.5802082945418277\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 {'eval_loss': 0.3654428055566369, 'eval_accuracy': 0.8064588616737826, 'eval_blue_score': 0.4638796137146781}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:5\tacc:0.7286444994301987 \t loss:0.5173888485223291\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 {'eval_loss': 0.30989974037264334, 'eval_accuracy': 0.8331835254084942, 'eval_blue_score': 0.5333742155627581}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:6\tacc:0.7467239439402299 \t loss:0.4691592994633381\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 {'eval_loss': 0.25836929357187316, 'eval_accuracy': 0.858688324612372, 'eval_blue_score': 0.6103597191551461}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:7\tacc:0.7627602955738609 \t loss:0.42965020543803695\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 {'eval_loss': 0.22046721980653025, 'eval_accuracy': 0.8805335302237488, 'eval_blue_score': 0.6779827867448665}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:8\tacc:0.7749248898344083 \t loss:0.4011964034141125\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 {'eval_loss': 0.19530869359997186, 'eval_accuracy': 0.8921222432666688, 'eval_blue_score': 0.7122706705837628}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:9\tacc:0.7855499365147438 \t loss:0.37670996739496304\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 {'eval_loss': 0.17914718208890973, 'eval_accuracy': 0.9009020577188533, 'eval_blue_score': 0.7389551826714676}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>▁▂▄▅▆▆▇███</td></tr><tr><td>eval_blue_score</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>eval_loss</td><td>█▆▄▃▃▂▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>0.9009</td></tr><tr><td>eval_blue_score</td><td>0.73896</td></tr><tr><td>eval_loss</td><td>0.17915</td></tr><tr><td>train_accuracy</td><td>0.78555</td></tr><tr><td>train_loss</td><td>0.37671</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">beaming-envelope-15</strong> at: <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/0hbwi35f\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/0hbwi35f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230202_164907-0hbwi35f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    with wandb.init(**trial) as exp:\n",
    "        train_dataset = WikiDataset(\n",
    "            exp.config.dataset_base_path,\n",
    "            exp.config.train_dataset_name,\n",
    "            exp.config.vocab_path,\n",
    "        )\n",
    "        train_dl = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=exp.config.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        exp.config.steps_per_epoch = len(train_dl)\n",
    "        exp.config.vocab_size = len(dev_dataset.entity_2_id.data)\n",
    "\n",
    "        dev_dataset = WikiDataset(\n",
    "            exp.config.dataset_base_path,\n",
    "            exp.config.dev_dataset_name,\n",
    "            exp.config.vocab_path,\n",
    "        )\n",
    "        dev_dl = DataLoader(\n",
    "            dev_dataset,\n",
    "            batch_size=exp.config.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # create model\n",
    "        model = GraphSeq(\n",
    "            emb_dim=exp.config.emb_dim,\n",
    "            vocab_size=exp.config.vocab_size,\n",
    "            pad_idx=exp.config.pad_idx,\n",
    "            graph_conv_layers=exp.config.graph_conv_layers,\n",
    "            rnn_decoder_layers=exp.config.rnn_layers,\n",
    "            rnn_dropout=exp.config.rnn_dropout,\n",
    "        )\n",
    "\n",
    "        # create optimizer\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=exp.config.learning_rate,\n",
    "        )\n",
    "\n",
    "        device = exp.config.device\n",
    "        # setup for training\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        model = model.to(device)\n",
    "\n",
    "        for epoch in range(exp.config.epochs):\n",
    "\n",
    "            metrics = train_fn(\n",
    "                model=model,\n",
    "                dataloader=dev_dl,\n",
    "                optimizer=optimizer,\n",
    "                steps_per_epoch=exp.config.steps_per_epoch,\n",
    "                device=device,\n",
    "                gradient_accumulation_steps=exp.config.accumulation_steps,\n",
    "                pad_idx=exp.config.pad_idx,\n",
    "                max_grad_norm=exp.config.max_grad_norm,\n",
    "            )\n",
    "\n",
    "            print(\"epoch:{epoch}\\tacc:{acc} \\t loss:{loss}\".format(\n",
    "                epoch=epoch,\n",
    "                acc=metrics[\"train_accuracy\"],\n",
    "                loss=metrics[\"train_loss\"],\n",
    "            ))\n",
    "            exp.log(metrics, step=epoch)\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                # eval every 1 epochs\n",
    "                is_best = False\n",
    "                scores = eval_fn(\n",
    "                    model=model,\n",
    "                    dataloader=dev_dl,\n",
    "                    device=device,\n",
    "                )\n",
    "\n",
    "                print(epoch, scores)\n",
    "                print()\n",
    "                exp.log(scores, step=epoch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5922706e",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "Eval attention component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857e6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"astrazeneca\"\n",
    "experiment_name = \"att-single-batch\"\n",
    "\n",
    "trials = [\n",
    "    # trial setup\n",
    "    dict(\n",
    "        job_type=\"train\",\n",
    "        project=project,\n",
    "        group=experiment_name,\n",
    "        notes=\"test training pipeline with a single batch on attention model\",\n",
    "        config=dict(\n",
    "            dataset_base_path=\"data/wiki\",\n",
    "            dataset_name=\"dev\",\n",
    "            vocab_path=\"data/wiki/entity_2_id.bin\",\n",
    "            batch_size=5,\n",
    "            learning_rate=0.003,\n",
    "            device=\"cuda\",\n",
    "            accumulation_steps=1,\n",
    "            max_grad_norm=20.,\n",
    "            epochs=500,\n",
    "            steps_per_epoch=5,\n",
    "            pad_idx=0,\n",
    "            emb_dim=6,\n",
    "            graph_conv_layers=1,\n",
    "            rnn_decoder_layers=1,\n",
    "            rnn_dropout=0.,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a36fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ando_cavallari/astra-zeneca/wandb/run-20230202_222429-9xmvctlz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andompesta/astrazeneca/runs/9xmvctlz\" target=\"_blank\">glowing-firecracker-49</a></strong> to <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/9xmvctlz\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/9xmvctlz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\tacc:0.0 \t loss:4.329547977447509\n",
      "epoch:1\tacc:0.0 \t loss:4.304247665405273\n",
      "epoch:2\tacc:0.0 \t loss:4.270625114440918\n",
      "epoch:3\tacc:0.0 \t loss:4.223822212219238\n",
      "epoch:4\tacc:0.0 \t loss:4.156934642791748\n",
      "epoch:5\tacc:0.029411764705882353 \t loss:4.062280368804932\n",
      "epoch:6\tacc:0.11176470588235295 \t loss:3.9368031501770018\n",
      "epoch:7\tacc:0.08823529411764706 \t loss:3.788045644760132\n",
      "epoch:8\tacc:0.08823529411764706 \t loss:3.62978138923645\n",
      "epoch:9\tacc:0.08823529411764706 \t loss:3.4729974269866943\n",
      "epoch:10\tacc:0.08823529411764706 \t loss:3.323265314102173\n",
      "epoch:11\tacc:0.08823529411764706 \t loss:3.1820910930633546\n",
      "epoch:12\tacc:0.08823529411764706 \t loss:3.0487760066986085\n",
      "epoch:13\tacc:0.08823529411764706 \t loss:2.9212154388427733\n",
      "epoch:14\tacc:0.08823529411764706 \t loss:2.7968277454376222\n",
      "epoch:15\tacc:0.08823529411764706 \t loss:2.6726473808288573\n",
      "epoch:16\tacc:0.08823529411764706 \t loss:2.545180606842041\n",
      "epoch:17\tacc:0.08823529411764706 \t loss:2.4110250949859617\n",
      "epoch:18\tacc:0.08823529411764706 \t loss:2.2676744937896727\n",
      "epoch:19\tacc:0.08823529411764706 \t loss:2.1000908851623534\n",
      "epoch:20\tacc:0.08823529411764706 \t loss:1.8206822156906128\n",
      "epoch:21\tacc:0.08823529411764706 \t loss:1.4345911264419555\n",
      "epoch:22\tacc:0.1 \t loss:1.3232309103012085\n",
      "epoch:23\tacc:0.14705882352941177 \t loss:1.2427552938461304\n",
      "epoch:24\tacc:0.14705882352941177 \t loss:1.1525100708007812\n",
      "epoch:25\tacc:0.14705882352941177 \t loss:1.086214303970337\n",
      "epoch:26\tacc:0.14705882352941177 \t loss:1.0478093147277832\n",
      "epoch:27\tacc:0.14705882352941177 \t loss:1.0288830041885375\n",
      "epoch:28\tacc:0.18235294117647058 \t loss:1.0188480138778686\n",
      "epoch:29\tacc:0.16470588235294117 \t loss:1.0087026357650757\n",
      "epoch:30\tacc:0.2 \t loss:0.9926405549049377\n",
      "epoch:31\tacc:0.20588235294117646 \t loss:0.9798593521118164\n",
      "epoch:32\tacc:0.20588235294117646 \t loss:0.9705038070678711\n",
      "epoch:33\tacc:0.21764705882352942 \t loss:0.9609068870544434\n",
      "epoch:34\tacc:0.23529411764705882 \t loss:0.9505706429481506\n",
      "epoch:35\tacc:0.25882352941176473 \t loss:0.9403571248054504\n",
      "epoch:36\tacc:0.27058823529411763 \t loss:0.9302056670188904\n",
      "epoch:37\tacc:0.2647058823529412 \t loss:0.9199908018112183\n",
      "epoch:38\tacc:0.2647058823529412 \t loss:0.9097840547561645\n",
      "epoch:39\tacc:0.25882352941176473 \t loss:0.8983732104301453\n",
      "epoch:40\tacc:0.2647058823529412 \t loss:0.8860545039176941\n",
      "epoch:41\tacc:0.2647058823529412 \t loss:0.8736441016197205\n",
      "epoch:42\tacc:0.2647058823529412 \t loss:0.8616601586341858\n",
      "epoch:43\tacc:0.28823529411764703 \t loss:0.8510547041893005\n",
      "epoch:44\tacc:0.29411764705882354 \t loss:0.8413447141647339\n",
      "epoch:45\tacc:0.3 \t loss:0.832537579536438\n",
      "epoch:46\tacc:0.3235294117647059 \t loss:0.8243271589279175\n",
      "epoch:47\tacc:0.3235294117647059 \t loss:0.8167255759239197\n",
      "epoch:48\tacc:0.3235294117647059 \t loss:0.8097057342529297\n",
      "epoch:49\tacc:0.3235294117647059 \t loss:0.8032164216041565\n",
      "epoch:50\tacc:0.3235294117647059 \t loss:0.7972032189369201\n",
      "epoch:51\tacc:0.3235294117647059 \t loss:0.7916362047195434\n",
      "epoch:52\tacc:0.3235294117647059 \t loss:0.786466121673584\n",
      "epoch:53\tacc:0.3235294117647059 \t loss:0.781640625\n",
      "epoch:54\tacc:0.3235294117647059 \t loss:0.777134108543396\n",
      "epoch:55\tacc:0.3235294117647059 \t loss:0.7729042887687683\n",
      "epoch:56\tacc:0.35294117647058826 \t loss:0.7688976764678955\n",
      "epoch:57\tacc:0.35294117647058826 \t loss:0.7650983572006226\n",
      "epoch:58\tacc:0.35294117647058826 \t loss:0.7614803314208984\n",
      "epoch:59\tacc:0.35294117647058826 \t loss:0.7580130696296692\n",
      "epoch:60\tacc:0.35294117647058826 \t loss:0.7546871900558472\n",
      "epoch:61\tacc:0.35294117647058826 \t loss:0.7514806270599366\n",
      "epoch:62\tacc:0.35294117647058826 \t loss:0.7483780384063721\n",
      "epoch:63\tacc:0.35294117647058826 \t loss:0.745376718044281\n",
      "epoch:64\tacc:0.35294117647058826 \t loss:0.7424681067466736\n",
      "epoch:65\tacc:0.35294117647058826 \t loss:0.7396409630775451\n",
      "epoch:66\tacc:0.35294117647058826 \t loss:0.7368841528892517\n",
      "epoch:67\tacc:0.35294117647058826 \t loss:0.7341950893402099\n",
      "epoch:68\tacc:0.35294117647058826 \t loss:0.7315744638442994\n",
      "epoch:69\tacc:0.35294117647058826 \t loss:0.7290181517601013\n",
      "epoch:70\tacc:0.35294117647058826 \t loss:0.7264868259429932\n",
      "epoch:71\tacc:0.3764705882352941 \t loss:0.7137209653854371\n",
      "epoch:72\tacc:0.38235294117647056 \t loss:0.7074840426445007\n",
      "epoch:73\tacc:0.38235294117647056 \t loss:0.7045940518379211\n",
      "epoch:74\tacc:0.38235294117647056 \t loss:0.7014399409294129\n",
      "epoch:75\tacc:0.38235294117647056 \t loss:0.6984199047088623\n",
      "epoch:76\tacc:0.38235294117647056 \t loss:0.6954498529434204\n",
      "epoch:77\tacc:0.38235294117647056 \t loss:0.6925828337669373\n",
      "epoch:78\tacc:0.38235294117647056 \t loss:0.689799678325653\n",
      "epoch:79\tacc:0.38235294117647056 \t loss:0.6870534539222717\n",
      "epoch:80\tacc:0.38235294117647056 \t loss:0.6843469738960266\n",
      "epoch:81\tacc:0.38235294117647056 \t loss:0.6816658616065979\n",
      "epoch:82\tacc:0.38235294117647056 \t loss:0.6789807438850403\n",
      "epoch:83\tacc:0.38235294117647056 \t loss:0.6762796878814697\n",
      "epoch:84\tacc:0.38235294117647056 \t loss:0.6735721111297608\n",
      "epoch:85\tacc:0.38235294117647056 \t loss:0.6708459377288818\n",
      "epoch:86\tacc:0.38235294117647056 \t loss:0.6681007623672486\n",
      "epoch:87\tacc:0.38235294117647056 \t loss:0.6651782035827637\n",
      "epoch:88\tacc:0.38235294117647056 \t loss:0.6620333194732666\n",
      "epoch:89\tacc:0.38235294117647056 \t loss:0.6586680769920349\n",
      "epoch:90\tacc:0.38235294117647056 \t loss:0.6551997900009155\n",
      "epoch:91\tacc:0.38235294117647056 \t loss:0.6517533302307129\n",
      "epoch:92\tacc:0.38235294117647056 \t loss:0.6483802914619445\n",
      "epoch:93\tacc:0.38235294117647056 \t loss:0.6451096653938293\n",
      "epoch:94\tacc:0.3941176470588235 \t loss:0.6419597506523133\n",
      "epoch:95\tacc:0.4117647058823529 \t loss:0.6389316916465759\n",
      "epoch:96\tacc:0.4117647058823529 \t loss:0.6360244989395142\n",
      "epoch:97\tacc:0.4117647058823529 \t loss:0.6332369089126587\n",
      "epoch:98\tacc:0.4117647058823529 \t loss:0.6305640697479248\n",
      "epoch:99\tacc:0.4117647058823529 \t loss:0.6279982924461365\n",
      "epoch:100\tacc:0.4117647058823529 \t loss:0.625528621673584\n",
      "epoch:101\tacc:0.4117647058823529 \t loss:0.6231524467468261\n",
      "epoch:102\tacc:0.4117647058823529 \t loss:0.6208580613136292\n",
      "epoch:103\tacc:0.4117647058823529 \t loss:0.6186427712440491\n",
      "epoch:104\tacc:0.4117647058823529 \t loss:0.6164983868598938\n",
      "epoch:105\tacc:0.4117647058823529 \t loss:0.6144151568412781\n",
      "epoch:106\tacc:0.4117647058823529 \t loss:0.6123849868774414\n",
      "epoch:107\tacc:0.4117647058823529 \t loss:0.6104076743125916\n",
      "epoch:108\tacc:0.4117647058823529 \t loss:0.6084790825843811\n",
      "epoch:109\tacc:0.4117647058823529 \t loss:0.6066043972969055\n",
      "epoch:110\tacc:0.4117647058823529 \t loss:0.6047573089599609\n",
      "epoch:111\tacc:0.4117647058823529 \t loss:0.6029523015022278\n",
      "epoch:112\tacc:0.4117647058823529 \t loss:0.6011828064918519\n",
      "epoch:113\tacc:0.4117647058823529 \t loss:0.5994540333747864\n",
      "epoch:114\tacc:0.4117647058823529 \t loss:0.5977652788162231\n",
      "epoch:115\tacc:0.4117647058823529 \t loss:0.5961168050765991\n",
      "epoch:116\tacc:0.4117647058823529 \t loss:0.5945096254348755\n",
      "epoch:117\tacc:0.4117647058823529 \t loss:0.5929370641708374\n",
      "epoch:118\tacc:0.4117647058823529 \t loss:0.5914024472236633\n",
      "epoch:119\tacc:0.4117647058823529 \t loss:0.589900279045105\n",
      "epoch:120\tacc:0.4117647058823529 \t loss:0.5884300351142884\n",
      "epoch:121\tacc:0.4117647058823529 \t loss:0.5869921088218689\n",
      "epoch:122\tacc:0.4117647058823529 \t loss:0.5855830430984497\n",
      "epoch:123\tacc:0.4117647058823529 \t loss:0.5842062711715699\n",
      "epoch:124\tacc:0.4117647058823529 \t loss:0.5828515768051148\n",
      "epoch:125\tacc:0.4117647058823529 \t loss:0.5815291166305542\n",
      "epoch:126\tacc:0.4117647058823529 \t loss:0.5802295684814454\n",
      "epoch:127\tacc:0.4117647058823529 \t loss:0.5789519786834717\n",
      "epoch:128\tacc:0.4117647058823529 \t loss:0.5777032732963562\n",
      "epoch:129\tacc:0.4117647058823529 \t loss:0.5764740347862244\n",
      "epoch:130\tacc:0.4117647058823529 \t loss:0.5752743601799011\n",
      "epoch:131\tacc:0.4117647058823529 \t loss:0.5740923762321473\n",
      "epoch:132\tacc:0.4117647058823529 \t loss:0.5729344487190247\n",
      "epoch:133\tacc:0.4117647058823529 \t loss:0.5717988848686218\n",
      "epoch:134\tacc:0.4117647058823529 \t loss:0.5706833004951477\n",
      "epoch:135\tacc:0.4117647058823529 \t loss:0.5695938110351563\n",
      "epoch:136\tacc:0.4117647058823529 \t loss:0.5685196995735169\n",
      "epoch:137\tacc:0.4117647058823529 \t loss:0.5674682497978211\n",
      "epoch:138\tacc:0.4117647058823529 \t loss:0.5664379596710205\n",
      "epoch:139\tacc:0.4117647058823529 \t loss:0.5654261946678162\n",
      "epoch:140\tacc:0.4117647058823529 \t loss:0.5644343614578247\n",
      "epoch:141\tacc:0.4117647058823529 \t loss:0.563461446762085\n",
      "epoch:142\tacc:0.4117647058823529 \t loss:0.5625073671340942\n",
      "epoch:143\tacc:0.4117647058823529 \t loss:0.5615699768066407\n",
      "epoch:144\tacc:0.4117647058823529 \t loss:0.5606544017791748\n",
      "epoch:145\tacc:0.4117647058823529 \t loss:0.5597611784934997\n",
      "epoch:146\tacc:0.4117647058823529 \t loss:0.5588893413543701\n",
      "epoch:147\tacc:0.4117647058823529 \t loss:0.5580395698547364\n",
      "epoch:148\tacc:0.4117647058823529 \t loss:0.5572105169296264\n",
      "epoch:149\tacc:0.4117647058823529 \t loss:0.5563972115516662\n",
      "epoch:150\tacc:0.4117647058823529 \t loss:0.5555979967117309\n",
      "epoch:151\tacc:0.4117647058823529 \t loss:0.5548135042190552\n",
      "epoch:152\tacc:0.4117647058823529 \t loss:0.5540440082550049\n",
      "epoch:153\tacc:0.4117647058823529 \t loss:0.5532881736755371\n",
      "epoch:154\tacc:0.4117647058823529 \t loss:0.55254567861557\n",
      "epoch:155\tacc:0.4117647058823529 \t loss:0.5518142104148864\n",
      "epoch:156\tacc:0.4117647058823529 \t loss:0.5511248946189881\n",
      "epoch:157\tacc:0.4117647058823529 \t loss:0.550409734249115\n",
      "epoch:158\tacc:0.4117647058823529 \t loss:0.5497187972068787\n",
      "epoch:159\tacc:0.4117647058823529 \t loss:0.5490268707275391\n",
      "epoch:160\tacc:0.4117647058823529 \t loss:0.5483350992202759\n",
      "epoch:161\tacc:0.4117647058823529 \t loss:0.547657585144043\n",
      "epoch:162\tacc:0.4117647058823529 \t loss:0.546988570690155\n",
      "epoch:163\tacc:0.4117647058823529 \t loss:0.5463317275047302\n",
      "epoch:164\tacc:0.4117647058823529 \t loss:0.5456807374954223\n",
      "epoch:165\tacc:0.4117647058823529 \t loss:0.5450405597686767\n",
      "epoch:166\tacc:0.4117647058823529 \t loss:0.5444083690643311\n",
      "epoch:167\tacc:0.4117647058823529 \t loss:0.5437860131263733\n",
      "epoch:168\tacc:0.4117647058823529 \t loss:0.5431734323501587\n",
      "epoch:169\tacc:0.4117647058823529 \t loss:0.5425670623779297\n",
      "epoch:170\tacc:0.4117647058823529 \t loss:0.5419826745986939\n",
      "epoch:171\tacc:0.4117647058823529 \t loss:0.5415434837341309\n",
      "epoch:172\tacc:0.4117647058823529 \t loss:0.5409121632575988\n",
      "epoch:173\tacc:0.4117647058823529 \t loss:0.5403324484825134\n",
      "epoch:174\tacc:0.4117647058823529 \t loss:0.5397536873817443\n",
      "epoch:175\tacc:0.4117647058823529 \t loss:0.5392090082168579\n",
      "epoch:176\tacc:0.4117647058823529 \t loss:0.5386919498443603\n",
      "epoch:177\tacc:0.4117647058823529 \t loss:0.5381793856620789\n",
      "epoch:178\tacc:0.4117647058823529 \t loss:0.5376742839813232\n",
      "epoch:179\tacc:0.4117647058823529 \t loss:0.5371798753738404\n",
      "epoch:180\tacc:0.4117647058823529 \t loss:0.5366945862770081\n",
      "epoch:181\tacc:0.4117647058823529 \t loss:0.5362159609794617\n",
      "epoch:182\tacc:0.4117647058823529 \t loss:0.5357452273368836\n",
      "epoch:183\tacc:0.4117647058823529 \t loss:0.5352809071540833\n",
      "epoch:184\tacc:0.4117647058823529 \t loss:0.5348234891891479\n",
      "epoch:185\tacc:0.4117647058823529 \t loss:0.5343792796134949\n",
      "epoch:186\tacc:0.4117647058823529 \t loss:0.5341941237449646\n",
      "epoch:187\tacc:0.4117647058823529 \t loss:0.5337916612625122\n",
      "epoch:188\tacc:0.4117647058823529 \t loss:0.5332184910774231\n",
      "epoch:189\tacc:0.4117647058823529 \t loss:0.5327414512634278\n",
      "epoch:190\tacc:0.4117647058823529 \t loss:0.532276737689972\n",
      "epoch:191\tacc:0.4117647058823529 \t loss:0.5318612456321716\n",
      "epoch:192\tacc:0.4117647058823529 \t loss:0.5314387440681457\n",
      "epoch:193\tacc:0.4117647058823529 \t loss:0.5310312271118164\n",
      "epoch:194\tacc:0.4117647058823529 \t loss:0.5306315183639526\n",
      "epoch:195\tacc:0.4117647058823529 \t loss:0.5302355885505676\n",
      "epoch:196\tacc:0.4117647058823529 \t loss:0.5298458933830261\n",
      "epoch:197\tacc:0.4117647058823529 \t loss:0.5294613242149353\n",
      "epoch:198\tacc:0.4117647058823529 \t loss:0.5290827035903931\n",
      "epoch:199\tacc:0.4117647058823529 \t loss:0.5287094235420227\n",
      "epoch:200\tacc:0.4117647058823529 \t loss:0.528339958190918\n",
      "epoch:201\tacc:0.4117647058823529 \t loss:0.5279747486114502\n",
      "epoch:202\tacc:0.4117647058823529 \t loss:0.5276138305664062\n",
      "epoch:203\tacc:0.4117647058823529 \t loss:0.5272574782371521\n",
      "epoch:204\tacc:0.4117647058823529 \t loss:0.5269053339958191\n",
      "epoch:205\tacc:0.4117647058823529 \t loss:0.5265575051307678\n",
      "epoch:206\tacc:0.4117647058823529 \t loss:0.5262132048606872\n",
      "epoch:207\tacc:0.4117647058823529 \t loss:0.525872778892517\n",
      "epoch:208\tacc:0.4117647058823529 \t loss:0.5255353808403015\n",
      "epoch:209\tacc:0.4117647058823529 \t loss:0.5252034902572632\n",
      "epoch:210\tacc:0.4117647058823529 \t loss:0.5249170660972595\n",
      "epoch:211\tacc:0.3941176470588235 \t loss:0.5365280747413635\n",
      "epoch:212\tacc:0.4 \t loss:0.5658538937568665\n",
      "epoch:213\tacc:0.40588235294117647 \t loss:0.5574975371360779\n",
      "epoch:214\tacc:0.4117647058823529 \t loss:0.5309513092041016\n",
      "epoch:215\tacc:0.4117647058823529 \t loss:0.5282797574996948\n",
      "epoch:216\tacc:0.4117647058823529 \t loss:0.5277461528778076\n",
      "epoch:217\tacc:0.4117647058823529 \t loss:0.525874924659729\n",
      "epoch:218\tacc:0.4117647058823529 \t loss:0.5257266163825989\n",
      "epoch:219\tacc:0.4117647058823529 \t loss:0.5250300288200378\n",
      "epoch:220\tacc:0.4117647058823529 \t loss:0.5244478821754456\n",
      "epoch:221\tacc:0.4117647058823529 \t loss:0.5240897297859192\n",
      "epoch:222\tacc:0.4117647058823529 \t loss:0.5236124873161316\n",
      "epoch:223\tacc:0.4117647058823529 \t loss:0.5232416033744812\n",
      "epoch:224\tacc:0.4117647058823529 \t loss:0.5228675723075866\n",
      "epoch:225\tacc:0.4117647058823529 \t loss:0.5225101709365845\n",
      "epoch:226\tacc:0.4117647058823529 \t loss:0.5221825242042542\n",
      "epoch:227\tacc:0.4117647058823529 \t loss:0.5218500018119812\n",
      "epoch:228\tacc:0.4117647058823529 \t loss:0.5215299606323243\n",
      "epoch:229\tacc:0.4117647058823529 \t loss:0.5212166786193848\n",
      "epoch:230\tacc:0.4117647058823529 \t loss:0.5209081411361695\n",
      "epoch:231\tacc:0.4117647058823529 \t loss:0.5206057786941528\n",
      "epoch:232\tacc:0.4117647058823529 \t loss:0.5203078866004944\n",
      "epoch:233\tacc:0.4117647058823529 \t loss:0.5200143575668335\n",
      "epoch:234\tacc:0.4117647058823529 \t loss:0.5197246432304382\n",
      "epoch:235\tacc:0.4117647058823529 \t loss:0.5194382667541504\n",
      "epoch:236\tacc:0.4117647058823529 \t loss:0.5191548943519593\n",
      "epoch:237\tacc:0.4117647058823529 \t loss:0.5188743233680725\n",
      "epoch:238\tacc:0.4117647058823529 \t loss:0.5185969233512878\n",
      "epoch:239\tacc:0.4117647058823529 \t loss:0.5183218002319336\n",
      "epoch:240\tacc:0.4117647058823529 \t loss:0.5180492758750915\n",
      "epoch:241\tacc:0.40588235294117647 \t loss:0.5177789688110351\n",
      "epoch:242\tacc:0.38823529411764707 \t loss:0.5175107598304749\n",
      "epoch:243\tacc:0.4117647058823529 \t loss:0.517244303226471\n",
      "epoch:244\tacc:0.4 \t loss:0.5169795036315918\n",
      "epoch:245\tacc:0.4117647058823529 \t loss:0.5167161107063294\n",
      "epoch:246\tacc:0.3941176470588235 \t loss:0.5164539694786072\n",
      "epoch:247\tacc:0.4 \t loss:0.5161927819252015\n",
      "epoch:248\tacc:0.4 \t loss:0.5159324407577515\n",
      "epoch:249\tacc:0.3941176470588235 \t loss:0.5156727075576782\n",
      "epoch:250\tacc:0.4117647058823529 \t loss:0.5154136061668396\n",
      "epoch:251\tacc:0.4117647058823529 \t loss:0.515154767036438\n",
      "epoch:252\tacc:0.4117647058823529 \t loss:0.5148958563804626\n",
      "epoch:253\tacc:0.4117647058823529 \t loss:0.5146369218826294\n",
      "epoch:254\tacc:0.4117647058823529 \t loss:0.514378023147583\n",
      "epoch:255\tacc:0.4117647058823529 \t loss:0.5141185402870179\n",
      "epoch:256\tacc:0.4117647058823529 \t loss:0.5138583898544311\n",
      "epoch:257\tacc:0.4117647058823529 \t loss:0.5135975360870362\n",
      "epoch:258\tacc:0.4117647058823529 \t loss:0.5133356213569641\n",
      "epoch:259\tacc:0.4117647058823529 \t loss:0.5130721211433411\n",
      "epoch:260\tacc:0.4117647058823529 \t loss:0.5128075122833252\n",
      "epoch:261\tacc:0.4117647058823529 \t loss:0.5125413656234741\n",
      "epoch:262\tacc:0.4117647058823529 \t loss:0.5122736096382141\n",
      "epoch:263\tacc:0.4117647058823529 \t loss:0.5120045185089112\n",
      "epoch:264\tacc:0.4117647058823529 \t loss:0.511733329296112\n",
      "epoch:265\tacc:0.4117647058823529 \t loss:0.5114606142044067\n",
      "epoch:266\tacc:0.4117647058823529 \t loss:0.5111873865127563\n",
      "epoch:267\tacc:0.4117647058823529 \t loss:0.5109172701835633\n",
      "epoch:268\tacc:0.4117647058823529 \t loss:0.5106457829475403\n",
      "epoch:269\tacc:0.4117647058823529 \t loss:0.5103726744651794\n",
      "epoch:270\tacc:0.4117647058823529 \t loss:0.5100983023643494\n",
      "epoch:271\tacc:0.4117647058823529 \t loss:0.5098227381706237\n",
      "epoch:272\tacc:0.4117647058823529 \t loss:0.5095466494560241\n",
      "epoch:273\tacc:0.4117647058823529 \t loss:0.5092736840248108\n",
      "epoch:274\tacc:0.4117647058823529 \t loss:0.5089996337890625\n",
      "epoch:275\tacc:0.4117647058823529 \t loss:0.5087266564369202\n",
      "epoch:276\tacc:0.4117647058823529 \t loss:0.5084542393684387\n",
      "epoch:277\tacc:0.4117647058823529 \t loss:0.5081827402114868\n",
      "epoch:278\tacc:0.4117647058823529 \t loss:0.5079124569892883\n",
      "epoch:279\tacc:0.4117647058823529 \t loss:0.5076436161994934\n",
      "epoch:280\tacc:0.4117647058823529 \t loss:0.5073767900466919\n",
      "epoch:281\tacc:0.4117647058823529 \t loss:0.5071121573448181\n",
      "epoch:282\tacc:0.4117647058823529 \t loss:0.5068499326705933\n",
      "epoch:283\tacc:0.4117647058823529 \t loss:0.506590461730957\n",
      "epoch:284\tacc:0.4117647058823529 \t loss:0.5063344001770019\n",
      "epoch:285\tacc:0.4117647058823529 \t loss:0.5060815453529358\n",
      "epoch:286\tacc:0.4117647058823529 \t loss:0.5058322548866272\n",
      "epoch:287\tacc:0.4117647058823529 \t loss:0.5055869698524476\n",
      "epoch:288\tacc:0.4117647058823529 \t loss:0.5053458333015441\n",
      "epoch:289\tacc:0.4117647058823529 \t loss:0.5051102995872497\n",
      "epoch:290\tacc:0.4117647058823529 \t loss:0.5048795700073242\n",
      "epoch:291\tacc:0.4117647058823529 \t loss:0.5046539545059204\n",
      "epoch:292\tacc:0.4117647058823529 \t loss:0.5044334292411804\n",
      "epoch:293\tacc:0.4117647058823529 \t loss:0.5042184352874756\n",
      "epoch:294\tacc:0.4117647058823529 \t loss:0.5040088057518005\n",
      "epoch:295\tacc:0.4117647058823529 \t loss:0.5038037776947022\n",
      "epoch:296\tacc:0.4117647058823529 \t loss:0.5036034703254699\n",
      "epoch:297\tacc:0.4117647058823529 \t loss:0.5034081220626831\n",
      "epoch:298\tacc:0.4117647058823529 \t loss:0.5032171368598938\n",
      "epoch:299\tacc:0.4117647058823529 \t loss:0.5030307173728943\n",
      "epoch:300\tacc:0.4117647058823529 \t loss:0.50284823179245\n",
      "epoch:301\tacc:0.4117647058823529 \t loss:0.5026695370674134\n",
      "epoch:302\tacc:0.4117647058823529 \t loss:0.502494478225708\n",
      "epoch:303\tacc:0.4117647058823529 \t loss:0.5023229002952576\n",
      "epoch:304\tacc:0.4117647058823529 \t loss:0.5021545052528381\n",
      "epoch:305\tacc:0.4117647058823529 \t loss:0.501989483833313\n",
      "epoch:306\tacc:0.4117647058823529 \t loss:0.5018269181251526\n",
      "epoch:307\tacc:0.4117647058823529 \t loss:0.5016671538352966\n",
      "epoch:308\tacc:0.4117647058823529 \t loss:0.5015100479125977\n",
      "epoch:309\tacc:0.4117647058823529 \t loss:0.5013551712036133\n",
      "epoch:310\tacc:0.4117647058823529 \t loss:0.5012027740478515\n",
      "epoch:311\tacc:0.4117647058823529 \t loss:0.501052725315094\n",
      "epoch:312\tacc:0.4117647058823529 \t loss:0.5009048700332641\n",
      "epoch:313\tacc:0.4117647058823529 \t loss:0.5007594108581543\n",
      "epoch:314\tacc:0.4117647058823529 \t loss:0.5006155729293823\n",
      "epoch:315\tacc:0.4117647058823529 \t loss:0.5004736661911011\n",
      "epoch:316\tacc:0.4117647058823529 \t loss:0.5003339052200317\n",
      "epoch:317\tacc:0.4117647058823529 \t loss:0.5001957893371582\n",
      "epoch:318\tacc:0.4117647058823529 \t loss:0.5000593304634094\n",
      "epoch:319\tacc:0.4117647058823529 \t loss:0.49992476105690004\n",
      "epoch:320\tacc:0.4117647058823529 \t loss:0.49979180097579956\n",
      "epoch:321\tacc:0.4117647058823529 \t loss:0.4996604919433594\n",
      "epoch:322\tacc:0.4117647058823529 \t loss:0.4995308220386505\n",
      "epoch:323\tacc:0.4117647058823529 \t loss:0.4994027495384216\n",
      "epoch:324\tacc:0.4117647058823529 \t loss:0.4992761790752411\n",
      "epoch:325\tacc:0.4117647058823529 \t loss:0.4991511762142181\n",
      "epoch:326\tacc:0.4117647058823529 \t loss:0.4990274488925934\n",
      "epoch:327\tacc:0.4117647058823529 \t loss:0.49890525341033937\n",
      "epoch:328\tacc:0.4117647058823529 \t loss:0.4987844944000244\n",
      "epoch:329\tacc:0.4117647058823529 \t loss:0.4986650884151459\n",
      "epoch:330\tacc:0.4117647058823529 \t loss:0.4985471606254578\n",
      "epoch:331\tacc:0.4117647058823529 \t loss:0.4984303772449493\n",
      "epoch:332\tacc:0.4117647058823529 \t loss:0.49831499457359313\n",
      "epoch:333\tacc:0.4117647058823529 \t loss:0.49820092916488645\n",
      "epoch:334\tacc:0.4117647058823529 \t loss:0.49808810353279115\n",
      "epoch:335\tacc:0.4117647058823529 \t loss:0.49797651171684265\n",
      "epoch:336\tacc:0.4117647058823529 \t loss:0.4978663206100464\n",
      "epoch:337\tacc:0.4117647058823529 \t loss:0.4977570414543152\n",
      "epoch:338\tacc:0.4117647058823529 \t loss:0.497649097442627\n",
      "epoch:339\tacc:0.4117647058823529 \t loss:0.4975422501564026\n",
      "epoch:340\tacc:0.4117647058823529 \t loss:0.49743654727935793\n",
      "epoch:341\tacc:0.4117647058823529 \t loss:0.49733213186264036\n",
      "epoch:342\tacc:0.4117647058823529 \t loss:0.49722861051559447\n",
      "epoch:343\tacc:0.4117647058823529 \t loss:0.49712625741958616\n",
      "epoch:344\tacc:0.4117647058823529 \t loss:0.49702503681182864\n",
      "epoch:345\tacc:0.4117647058823529 \t loss:0.4969246804714203\n",
      "epoch:346\tacc:0.4117647058823529 \t loss:0.4968255519866943\n",
      "epoch:347\tacc:0.4117647058823529 \t loss:0.49672757983207705\n",
      "epoch:348\tacc:0.4117647058823529 \t loss:0.49663019776344297\n",
      "epoch:349\tacc:0.4117647058823529 \t loss:0.49653398990631104\n",
      "epoch:350\tacc:0.4117647058823529 \t loss:0.4964388728141785\n",
      "epoch:351\tacc:0.4117647058823529 \t loss:0.4963446080684662\n",
      "epoch:352\tacc:0.4117647058823529 \t loss:0.4962512731552124\n",
      "epoch:353\tacc:0.4117647058823529 \t loss:0.4961588382720947\n",
      "epoch:354\tacc:0.4117647058823529 \t loss:0.4960674226284027\n",
      "epoch:355\tacc:0.4117647058823529 \t loss:0.49597703814506533\n",
      "epoch:356\tacc:0.4117647058823529 \t loss:0.4958873152732849\n",
      "epoch:357\tacc:0.4117647058823529 \t loss:0.4957985162734985\n",
      "epoch:358\tacc:0.4117647058823529 \t loss:0.49571065306663514\n",
      "epoch:359\tacc:0.4117647058823529 \t loss:0.49562354683876036\n",
      "epoch:360\tacc:0.4117647058823529 \t loss:0.4955372393131256\n",
      "epoch:361\tacc:0.4117647058823529 \t loss:0.49545189142227175\n",
      "epoch:362\tacc:0.4117647058823529 \t loss:0.49536728858947754\n",
      "epoch:363\tacc:0.4117647058823529 \t loss:0.49528337121009824\n",
      "epoch:364\tacc:0.4117647058823529 \t loss:0.49520031809806825\n",
      "epoch:365\tacc:0.4117647058823529 \t loss:0.49511800408363343\n",
      "epoch:366\tacc:0.4117647058823529 \t loss:0.49503645300865173\n",
      "epoch:367\tacc:0.4117647058823529 \t loss:0.4949556767940521\n",
      "epoch:368\tacc:0.4117647058823529 \t loss:0.4948756456375122\n",
      "epoch:369\tacc:0.4117647058823529 \t loss:0.4947964608669281\n",
      "epoch:370\tacc:0.4117647058823529 \t loss:0.49471781253814695\n",
      "epoch:371\tacc:0.4117647058823529 \t loss:0.4946397662162781\n",
      "epoch:372\tacc:0.4117647058823529 \t loss:0.4945625901222229\n",
      "epoch:373\tacc:0.4117647058823529 \t loss:0.49448607563972474\n",
      "epoch:374\tacc:0.4117647058823529 \t loss:0.4944101691246033\n",
      "epoch:375\tacc:0.4117647058823529 \t loss:0.4943349778652191\n",
      "epoch:376\tacc:0.4117647058823529 \t loss:0.49426048398017886\n",
      "epoch:377\tacc:0.4117647058823529 \t loss:0.49418656826019286\n",
      "epoch:378\tacc:0.4117647058823529 \t loss:0.494113564491272\n",
      "epoch:379\tacc:0.4117647058823529 \t loss:0.4940408289432526\n",
      "epoch:380\tacc:0.4117647058823529 \t loss:0.4939687967300415\n",
      "epoch:381\tacc:0.4117647058823529 \t loss:0.4938975155353546\n",
      "epoch:382\tacc:0.4117647058823529 \t loss:0.4938267171382904\n",
      "epoch:383\tacc:0.4117647058823529 \t loss:0.4937565326690674\n",
      "epoch:384\tacc:0.4117647058823529 \t loss:0.4936869442462921\n",
      "epoch:385\tacc:0.4117647058823529 \t loss:0.49361867308616636\n",
      "epoch:386\tacc:0.4117647058823529 \t loss:0.49354976415634155\n",
      "epoch:387\tacc:0.4117647058823529 \t loss:0.4934819877147675\n",
      "epoch:388\tacc:0.4117647058823529 \t loss:0.49341467022895813\n",
      "epoch:389\tacc:0.4117647058823529 \t loss:0.49334810972213744\n",
      "epoch:390\tacc:0.4117647058823529 \t loss:0.49328998327255247\n",
      "epoch:391\tacc:0.4117647058823529 \t loss:0.4932208240032196\n",
      "epoch:392\tacc:0.4117647058823529 \t loss:0.493163651227951\n",
      "epoch:393\tacc:0.4117647058823529 \t loss:0.49311344027519227\n",
      "epoch:394\tacc:0.4117647058823529 \t loss:0.49303890466690065\n",
      "epoch:395\tacc:0.4117647058823529 \t loss:0.4929678201675415\n",
      "epoch:396\tacc:0.4117647058823529 \t loss:0.49290038347244264\n",
      "epoch:397\tacc:0.4117647058823529 \t loss:0.4928362131118774\n",
      "epoch:398\tacc:0.4117647058823529 \t loss:0.49277458190917967\n",
      "epoch:399\tacc:0.4117647058823529 \t loss:0.4927125334739685\n",
      "epoch:400\tacc:0.4117647058823529 \t loss:0.4926512181758881\n",
      "epoch:401\tacc:0.4117647058823529 \t loss:0.4925904214382172\n",
      "epoch:402\tacc:0.4117647058823529 \t loss:0.49253053069114683\n",
      "epoch:403\tacc:0.4117647058823529 \t loss:0.4924715876579285\n",
      "epoch:404\tacc:0.4117647058823529 \t loss:0.4924124240875244\n",
      "epoch:405\tacc:0.4117647058823529 \t loss:0.49235341548919676\n",
      "epoch:406\tacc:0.4117647058823529 \t loss:0.4922957241535187\n",
      "epoch:407\tacc:0.4117647058823529 \t loss:0.4922380864620209\n",
      "epoch:408\tacc:0.4117647058823529 \t loss:0.4921805202960968\n",
      "epoch:409\tacc:0.4117647058823529 \t loss:0.4921243071556091\n",
      "epoch:410\tacc:0.4117647058823529 \t loss:0.49206777215003966\n",
      "epoch:411\tacc:0.4117647058823529 \t loss:0.4920119822025299\n",
      "epoch:412\tacc:0.4117647058823529 \t loss:0.4919566214084625\n",
      "epoch:413\tacc:0.4117647058823529 \t loss:0.4919012188911438\n",
      "epoch:414\tacc:0.4117647058823529 \t loss:0.49184610247612\n",
      "epoch:415\tacc:0.4117647058823529 \t loss:0.4917918026447296\n",
      "epoch:416\tacc:0.4117647058823529 \t loss:0.49173819422721865\n",
      "epoch:417\tacc:0.4117647058823529 \t loss:0.49168447256088255\n",
      "epoch:418\tacc:0.4117647058823529 \t loss:0.49163155555725097\n",
      "epoch:419\tacc:0.4117647058823529 \t loss:0.4915786385536194\n",
      "epoch:420\tacc:0.4117647058823529 \t loss:0.49152734875679016\n",
      "epoch:421\tacc:0.4117647058823529 \t loss:0.49147512912750246\n",
      "epoch:422\tacc:0.4117647058823529 \t loss:0.491423100233078\n",
      "epoch:423\tacc:0.4117647058823529 \t loss:0.49137450456619264\n",
      "epoch:424\tacc:0.4117647058823529 \t loss:0.4913221478462219\n",
      "epoch:425\tacc:0.4117647058823529 \t loss:0.4912704110145569\n",
      "epoch:426\tacc:0.4117647058823529 \t loss:0.4912212729454041\n",
      "epoch:427\tacc:0.4117647058823529 \t loss:0.49117511510849\n",
      "epoch:428\tacc:0.4117647058823529 \t loss:0.491127747297287\n",
      "epoch:429\tacc:0.4117647058823529 \t loss:0.4910755634307861\n",
      "epoch:430\tacc:0.4117647058823529 \t loss:0.49102360010147095\n",
      "epoch:431\tacc:0.4117647058823529 \t loss:0.4910208761692047\n",
      "epoch:432\tacc:0.4117647058823529 \t loss:0.4909527063369751\n",
      "epoch:433\tacc:0.4117647058823529 \t loss:0.4908970773220062\n",
      "epoch:434\tacc:0.4117647058823529 \t loss:0.49084282517433164\n",
      "epoch:435\tacc:0.4117647058823529 \t loss:0.4907909631729126\n",
      "epoch:436\tacc:0.4117647058823529 \t loss:0.4907416820526123\n",
      "epoch:437\tacc:0.4117647058823529 \t loss:0.4906937003135681\n",
      "epoch:438\tacc:0.4117647058823529 \t loss:0.49064652919769286\n",
      "epoch:439\tacc:0.4117647058823529 \t loss:0.4906054437160492\n",
      "epoch:440\tacc:0.4117647058823529 \t loss:0.49056432247161863\n",
      "epoch:441\tacc:0.4117647058823529 \t loss:0.49051526188850403\n",
      "epoch:442\tacc:0.4117647058823529 \t loss:0.49046758413314817\n",
      "epoch:443\tacc:0.4117647058823529 \t loss:0.4904213547706604\n",
      "epoch:444\tacc:0.4117647058823529 \t loss:0.49044857621192933\n",
      "epoch:445\tacc:0.4117647058823529 \t loss:0.4904038727283478\n",
      "epoch:446\tacc:0.4117647058823529 \t loss:0.49033525586128235\n",
      "epoch:447\tacc:0.4117647058823529 \t loss:0.4902775466442108\n",
      "epoch:448\tacc:0.4117647058823529 \t loss:0.49022371768951417\n",
      "epoch:449\tacc:0.4117647058823529 \t loss:0.4901712477207184\n",
      "epoch:450\tacc:0.4117647058823529 \t loss:0.4901249408721924\n",
      "epoch:451\tacc:0.4117647058823529 \t loss:0.4900794565677643\n",
      "epoch:452\tacc:0.4117647058823529 \t loss:0.490035754442215\n",
      "epoch:453\tacc:0.4117647058823529 \t loss:0.48999311923980715\n",
      "epoch:454\tacc:0.4117647058823529 \t loss:0.4899507999420166\n",
      "epoch:455\tacc:0.4117647058823529 \t loss:0.4899096190929413\n",
      "epoch:456\tacc:0.4117647058823529 \t loss:0.4898685157299042\n",
      "epoch:457\tacc:0.4117647058823529 \t loss:0.489827835559845\n",
      "epoch:458\tacc:0.4117647058823529 \t loss:0.4897870659828186\n",
      "epoch:459\tacc:0.4117647058823529 \t loss:0.48974673748016356\n",
      "epoch:460\tacc:0.4117647058823529 \t loss:0.48970717191696167\n",
      "epoch:461\tacc:0.4117647058823529 \t loss:0.48966742753982545\n",
      "epoch:462\tacc:0.4117647058823529 \t loss:0.48962790369987486\n",
      "epoch:463\tacc:0.4117647058823529 \t loss:0.489588463306427\n",
      "epoch:464\tacc:0.4117647058823529 \t loss:0.48954989314079284\n",
      "epoch:465\tacc:0.4117647058823529 \t loss:0.4895113825798035\n",
      "epoch:466\tacc:0.4117647058823529 \t loss:0.4894727110862732\n",
      "epoch:467\tacc:0.4117647058823529 \t loss:0.48943510055541994\n",
      "epoch:468\tacc:0.4117647058823529 \t loss:0.48939743638038635\n",
      "epoch:469\tacc:0.4117647058823529 \t loss:0.4893593192100525\n",
      "epoch:470\tacc:0.4117647058823529 \t loss:0.48932166695594786\n",
      "epoch:471\tacc:0.4117647058823529 \t loss:0.48928544521331785\n",
      "epoch:472\tacc:0.4117647058823529 \t loss:0.4892519056797028\n",
      "epoch:473\tacc:0.4117647058823529 \t loss:0.4892196714878082\n",
      "epoch:474\tacc:0.4117647058823529 \t loss:0.48919735550880433\n",
      "epoch:475\tacc:0.4117647058823529 \t loss:0.48914334177970886\n",
      "epoch:476\tacc:0.4117647058823529 \t loss:0.48911007046699523\n",
      "epoch:477\tacc:0.4117647058823529 \t loss:0.4890817224979401\n",
      "epoch:478\tacc:0.4117647058823529 \t loss:0.4890388548374176\n",
      "epoch:479\tacc:0.4117647058823529 \t loss:0.48900042176246644\n",
      "epoch:480\tacc:0.4117647058823529 \t loss:0.4889621913433075\n",
      "epoch:481\tacc:0.4117647058823529 \t loss:0.48892573118209837\n",
      "epoch:482\tacc:0.4117647058823529 \t loss:0.48889033794403075\n",
      "epoch:483\tacc:0.4117647058823529 \t loss:0.4888552904129028\n",
      "epoch:484\tacc:0.4117647058823529 \t loss:0.48882046341896057\n",
      "epoch:485\tacc:0.4117647058823529 \t loss:0.48878936767578124\n",
      "epoch:486\tacc:0.4117647058823529 \t loss:0.4887592732906342\n",
      "epoch:487\tacc:0.4117647058823529 \t loss:0.48872244358062744\n",
      "epoch:488\tacc:0.4117647058823529 \t loss:0.4886866807937622\n",
      "epoch:489\tacc:0.4117647058823529 \t loss:0.488662052154541\n",
      "epoch:490\tacc:0.4117647058823529 \t loss:0.4886579871177673\n",
      "epoch:491\tacc:0.4117647058823529 \t loss:0.4886085748672485\n",
      "epoch:492\tacc:0.4117647058823529 \t loss:0.48856704831123354\n",
      "epoch:493\tacc:0.4117647058823529 \t loss:0.48852705359458926\n",
      "epoch:494\tacc:0.4117647058823529 \t loss:0.48849196434020997\n",
      "epoch:495\tacc:0.4117647058823529 \t loss:0.4884573400020599\n",
      "epoch:496\tacc:0.4117647058823529 \t loss:0.4884342610836029\n",
      "epoch:497\tacc:0.4117647058823529 \t loss:0.4884077787399292\n",
      "epoch:498\tacc:0.4117647058823529 \t loss:0.4883707404136658\n",
      "epoch:499\tacc:0.4117647058823529 \t loss:0.48833560943603516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▃▄▅▇▇██████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.41176</td></tr><tr><td>train_loss</td><td>0.48834</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-firecracker-49</strong> at: <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/9xmvctlz\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/9xmvctlz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230202_222429-9xmvctlz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    with wandb.init(**trial) as exp:\n",
    "        dev_dataset = WikiDataset(\n",
    "            exp.config.dataset_base_path,\n",
    "            exp.config.dataset_name,\n",
    "            exp.config.vocab_path,\n",
    "        )\n",
    "        exp.config[\"vocab_size\"] = len(dev_dataset.entity_2_id.data)\n",
    "\n",
    "        dev_dl = DataLoader(\n",
    "            dev_dataset,\n",
    "            batch_size=exp.config.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # as it is a single batch experiment\n",
    "        batch_data = next(iter(dev_dl))\n",
    "        dev_dl = [batch_data] * exp.config.steps_per_epoch\n",
    "\n",
    "        # create model\n",
    "        model = GraphSeqAttn(\n",
    "            emb_dim=exp.config.emb_dim,\n",
    "            vocab_size=exp.config.vocab_size,\n",
    "            pad_idx=exp.config.pad_idx,\n",
    "            graph_conv_layers=exp.config.graph_conv_layers,\n",
    "            rnn_decoder_layers=exp.config.rnn_decoder_layers,\n",
    "            rnn_dropout=exp.config.rnn_dropout,\n",
    "        )\n",
    "\n",
    "        # create optimizer\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=exp.config.learning_rate,\n",
    "        )\n",
    "\n",
    "        # setup for training\n",
    "        device = exp.config.device\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        model = model.to(device)\n",
    "\n",
    "        for epoch in range(exp.config.epochs):\n",
    "\n",
    "            metrics = train_fn(\n",
    "                model=model,\n",
    "                dataloader=dev_dl,\n",
    "                optimizer=optimizer,\n",
    "                steps_per_epoch=exp.config.steps_per_epoch,\n",
    "                device=device,\n",
    "                gradient_accumulation_steps=exp.config.accumulation_steps,\n",
    "                pad_idx=exp.config.pad_idx,\n",
    "                max_grad_norm=exp.config.max_grad_norm,\n",
    "            )\n",
    "\n",
    "            print(\"epoch:{epoch}\\tacc:{acc} \\t loss:{loss}\".format(\n",
    "                epoch=epoch,\n",
    "                acc=metrics[\"train_accuracy\"],\n",
    "                loss=metrics[\"train_loss\"],\n",
    "            ))\n",
    "            exp.log(metrics, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16f0176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   4,   40,    6,   34,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "             3,    3,    3,    3,    3],\n",
       "         [   4,   17,   34,    2,   35,    2,    2,   35,   35,   35,   35,   35,\n",
       "            35,   35,   35,   35,   35],\n",
       "         [   4,   34,    2,   35,    2,    2,   35,   35,   35,   35,   35,   35,\n",
       "            35,   35,   35,   35,   35],\n",
       "         [   4,   42,    6,   35, 1061, 1061,   35,   35,   35,   35,   35,   35,\n",
       "            35,   35,   35,   35,   35],\n",
       "         [   4,   42,    6,   40,    5,    5,    5,    5,    5, 5271, 5271,    2,\n",
       "             2,    2,    2,    2,    2]], device='cuda:0'),\n",
       " tensor([[    4,    40,     6,    34,     3,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    17,    34,     6,    35,   227,     2,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    34,     6,    35,   681,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    42,     6,    35,  1061,     2,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    4,    42,     6,    40,  5271,     5,    37, 14416,     2,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]], device='cuda:0'),\n",
       " tensor([[    1,     4,    40,     6,    34,     3,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    17,    34,     6,    35,   227,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    34,     6,    35,   681,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    42,     6,    35,  1061,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,     4,    42,     6,    40,  5271,     5,    37, 14416,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize predictions\n",
    "logits = model(\n",
    "    batch_data.x,\n",
    "    batch_data.src_seq,\n",
    "    batch_data.edge_index,\n",
    "    batch_data.bw_edge_index,\n",
    "    batch_data.batch,\n",
    ")\n",
    "\n",
    "preds = logits.softmax(-1).argmax(-1)\n",
    "preds, batch_data.trg_seq, batch_data.src_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae322092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (batch_data.trg_seq != 0).view(-1)\n",
    "l = batch_data.trg_seq.view(-1)\n",
    "p = preds.view(-1)\n",
    "\n",
    "p, l, mask\n",
    "p[mask] == l[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549ef2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"astrazeneca\"\n",
    "experiment_name = \"att-graph-seq train and eval\"\n",
    "\n",
    "trials = [\n",
    "    # trial setup\n",
    "    dict(\n",
    "        job_type=\"train\",\n",
    "        project=project,\n",
    "        group=experiment_name,\n",
    "        notes=\"training and validation pipeline on the entire dataset\",\n",
    "        config=dict(\n",
    "            dataset_base_path=\"data/wiki\",\n",
    "            train_dataset_name=\"train\",\n",
    "            dev_dataset_name=\"dev\",\n",
    "            vocab_path=\"data/wiki/entity_2_id.bin\",\n",
    "            batch_size=64,\n",
    "            learning_rate=0.003,\n",
    "            device=\"cuda\",\n",
    "            accumulation_steps=1,\n",
    "            max_grad_norm=10.,\n",
    "            epochs=10,\n",
    "            pad_idx=0,\n",
    "            emb_dim=60,\n",
    "            graph_conv_layers=3,\n",
    "            rnn_layers=2,\n",
    "            rnn_dropout=0.25,\n",
    "            ckp_base_path=\"ckps\",\n",
    "            optim_method=\"adam\",\n",
    "            weight_decay=0.001,\n",
    "            warmup_persentage=2.5,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ae7c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ando_cavallari/astra-zeneca/wandb/run-20230202_235941-3who7l5v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/andompesta/astrazeneca/runs/3who7l5v\" target=\"_blank\">fortuitous-lantern-63</a></strong> to <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/andompesta/astrazeneca\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/3who7l5v\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/3who7l5v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:0\tacc:0.3558619659468459 \t loss:2.177056984381833\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'eval_loss': 1.285157428094835, 'eval_accuracy': 0.5313312574235177, 'eval_blue_score': 0.057201265253471086}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:1\tacc:0.563337083822222 \t loss:1.1533790481077015\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'eval_loss': 0.9012198242725749, 'eval_accuracy': 0.618342910339957, 'eval_blue_score': 0.12149704467490718}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:2\tacc:0.622430172241403 \t loss:0.8674439771627325\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {'eval_loss': 0.6783349313067667, 'eval_accuracy': 0.6792879843343713, 'eval_blue_score': 0.22622212037206707}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:3\tacc:0.6718643463427915 \t loss:0.67993181950659\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 {'eval_loss': 0.5193604655338057, 'eval_accuracy': 0.7336361593528298, 'eval_blue_score': 0.34496388573903664}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:4\tacc:0.7094953223292223 \t loss:0.5654873748507592\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 {'eval_loss': 0.4217682887207378, 'eval_accuracy': 0.7739237905685211, 'eval_blue_score': 0.43810381629577494}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:5\tacc:0.7456204810423629 \t loss:0.47774256520590636\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 {'eval_loss': 0.3320292842884858, 'eval_accuracy': 0.8216590157619338, 'eval_blue_score': 0.5574015385680758}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:6\tacc:0.7722698328181431 \t loss:0.4176410717232138\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 {'eval_loss': 0.28717275319451635, 'eval_accuracy': 0.8444512214696157, 'eval_blue_score': 0.6248094364721009}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:7\tacc:0.7953244975991249 \t loss:0.3697721321520551\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 {'eval_loss': 0.24542989017385425, 'eval_accuracy': 0.8692497833135373, 'eval_blue_score': 0.6956498168046662}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:8\tacc:0.8128088431227518 \t loss:0.33710634380274546\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 {'eval_loss': 0.21265378230336038, 'eval_accuracy': 0.8907739719431158, 'eval_blue_score': 0.7553751494545705}\n",
      "\n",
      "batch : 50\n",
      "batch : 100\n",
      "batch : 150\n",
      "batch : 200\n",
      "batch : 250\n",
      "batch : 300\n",
      "batch : 350\n",
      "batch : 400\n",
      "batch : 450\n",
      "batch : 500\n",
      "batch : 550\n",
      "batch : 600\n",
      "batch : 650\n",
      "batch : 700\n",
      "batch : 750\n",
      "batch : 800\n",
      "batch : 850\n",
      "epoch:9\tacc:0.8245566271620525 \t loss:0.31656004853808783\n",
      "eval batch : 50\n",
      "eval batch : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 {'eval_loss': 0.19587659991035858, 'eval_accuracy': 0.9005489390388751, 'eval_blue_score': 0.7858861646757241}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>▁▃▄▅▆▇▇▇██</td></tr><tr><td>eval_blue_score</td><td>▁▂▃▄▅▆▆▇██</td></tr><tr><td>eval_loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_accuracy</td><td>0.90055</td></tr><tr><td>eval_blue_score</td><td>0.78589</td></tr><tr><td>eval_loss</td><td>0.19588</td></tr><tr><td>train_accuracy</td><td>0.82456</td></tr><tr><td>train_loss</td><td>0.31656</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fortuitous-lantern-63</strong> at: <a href=\"https://wandb.ai/andompesta/astrazeneca/runs/3who7l5v\" target=\"_blank\">https://wandb.ai/andompesta/astrazeneca/runs/3who7l5v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230202_235941-3who7l5v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trial in trials:\n",
    "    with wandb.init(**trial) as exp:\n",
    "        train_dataset = WikiDataset(\n",
    "            exp.config.dataset_base_path,\n",
    "            exp.config.train_dataset_name,\n",
    "            exp.config.vocab_path,\n",
    "        )\n",
    "        train_dl = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=exp.config.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        # scheduler parameters\n",
    "        exp.config.batches_per_epoch = len(train_dl)\n",
    "        exp.config.steps_per_epoch = int(\n",
    "            exp.config.batches_per_epoch / exp.config.accumulation_steps\n",
    "        )\n",
    "        exp.config.num_warmup_steps = exp.config.steps_per_epoch * exp.config.warmup_persentage\n",
    "        exp.config.num_training_steps = int(exp.config.steps_per_epoch * exp.config.epochs)\n",
    "\n",
    "        exp.config.vocab_size = len(train_dataset.entity_2_id.data)\n",
    "\n",
    "        dev_dataset = WikiDataset(\n",
    "            exp.config.dataset_base_path,\n",
    "            exp.config.dev_dataset_name,\n",
    "            exp.config.vocab_path,\n",
    "        )\n",
    "        dev_dl = DataLoader(\n",
    "            dev_dataset,\n",
    "            batch_size=exp.config.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # create model\n",
    "        model = GraphSeqAttn(\n",
    "            emb_dim=exp.config.emb_dim,\n",
    "            vocab_size=exp.config.vocab_size,\n",
    "            pad_idx=exp.config.pad_idx,\n",
    "            graph_conv_layers=exp.config.graph_conv_layers,\n",
    "            rnn_decoder_layers=exp.config.rnn_layers,\n",
    "            rnn_dropout=exp.config.rnn_dropout,\n",
    "        )\n",
    "\n",
    "        # setup optimizers\n",
    "        named_params = list(model.named_parameters())\n",
    "        group_params = get_group_params(\n",
    "            named_params,\n",
    "            exp.config.weight_decay,\n",
    "            no_decay=[\"bias\"],\n",
    "        )\n",
    "        optimizer = get_optimizer(\n",
    "            method=exp.config.optim_method,\n",
    "            params=group_params,\n",
    "            lr=exp.config.learning_rate,\n",
    "        )\n",
    "        scheduler = get_linear_scheduler_with_warmup(\n",
    "            optimizer,\n",
    "            exp.config.num_warmup_steps,\n",
    "            exp.config.num_training_steps,\n",
    "        )\n",
    "\n",
    "        device = exp.config.device\n",
    "        # setup for training\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        model = model.to(device)\n",
    "\n",
    "        ckp_path = Path(exp.config.ckp_base_path).joinpath(exp.name)\n",
    "        ckp_path.mkdir(\n",
    "            parents=True,\n",
    "            exist_ok=True,\n",
    "        )\n",
    "        best_blue_score = float(\"-inf\")\n",
    "\n",
    "        for epoch in range(exp.config.epochs):\n",
    "\n",
    "            metrics = train_fn(\n",
    "                model=model,\n",
    "                dataloader=dev_dl,\n",
    "                optimizer=optimizer,\n",
    "                steps_per_epoch=exp.config.steps_per_epoch,\n",
    "                scheduler=scheduler,\n",
    "                device=device,\n",
    "                gradient_accumulation_steps=exp.config.accumulation_steps,\n",
    "                pad_idx=exp.config.pad_idx,\n",
    "                max_grad_norm=exp.config.max_grad_norm,\n",
    "            )\n",
    "\n",
    "            print(\"epoch:{epoch}\\tacc:{acc} \\t loss:{loss}\".format(\n",
    "                epoch=epoch,\n",
    "                acc=metrics[\"train_accuracy\"],\n",
    "                loss=metrics[\"train_loss\"],\n",
    "            ))\n",
    "            exp.log(metrics, step=epoch)\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                # eval every 1 epochs\n",
    "                is_best = False\n",
    "                scores = eval_fn(\n",
    "                    model=model,\n",
    "                    dataloader=dev_dl,\n",
    "                    device=device,\n",
    "                )\n",
    "\n",
    "                print(epoch, scores)\n",
    "                print()\n",
    "                exp.log(scores, step=epoch)\n",
    "\n",
    "                if scores[\"eval_blue_score\"] > best_blue_score:\n",
    "                    best_blue_score = scores[\"eval_blue_score\"]\n",
    "                    is_best = True\n",
    "\n",
    "                if isinstance(model, torch.nn.DataParallel):\n",
    "                    state_dict = dict([\n",
    "                        (n, p.to(\"cpu\"))\n",
    "                        for n, p in model.module.state_dict().items()\n",
    "                    ])\n",
    "                else:\n",
    "                    state_dict = dict([\n",
    "                        (n, p.to(\"cpu\")) for n, p in model.state_dict().items()\n",
    "                    ])\n",
    "\n",
    "                save_checkpoint(\n",
    "                    path_=ckp_path,\n",
    "                    state=state_dict,\n",
    "                    is_best=is_best,\n",
    "                    filename=f\"ckp_{epoch}.pth.tar\",\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ad89c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval batch : 50\n",
      "eval batch : 100\n",
      "eval batch : 150\n",
      "eval batch : 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/envs/geometric/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0348684235988372,\n",
       " 'eval_accuracy': 0.7476343373596317,\n",
       " 'eval_blue_score': 0.4024570087621595}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = WikiDataset(\n",
    "    exp.config.dataset_base_path,\n",
    "    \"test\",\n",
    "    exp.config.vocab_path,\n",
    ")\n",
    "test_dl = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=exp.config.batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "\n",
    "sate_dict = torch.load(ckp_path.joinpath(\"model_best.pth.tar\"))\n",
    "model = GraphSeqAttn(\n",
    "    emb_dim=exp.config.emb_dim,\n",
    "    vocab_size=exp.config.vocab_size,\n",
    "    pad_idx=exp.config.pad_idx,\n",
    "    graph_conv_layers=exp.config.graph_conv_layers,\n",
    "    rnn_decoder_layers=exp.config.rnn_layers,\n",
    "    rnn_dropout=exp.config.rnn_dropout,\n",
    ")\n",
    "model.load_state_dict(sate_dict)\n",
    "model = model.to(device)\n",
    "\n",
    "scores = eval_fn(\n",
    "    model=model,\n",
    "    dataloader=test_dl,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1debeed81619785a8d6b1d6ab4f3be2c289b30083acd6f537a7446573ac7344f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
